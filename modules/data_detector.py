import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from typing import Dict, Any, List, Tuple
import chardet
import platform

class DataDetector:
    def __init__(self):
        # í•œê¸€ í°íŠ¸ ì„¤ì •
        self.set_korean_font()
    
    def set_korean_font(self):
        """ìš´ì˜ì²´ì œë³„ í•œê¸€ í°íŠ¸ ì„¤ì •"""
        system = platform.system()
        
        if system == 'Windows':
            plt.rcParams['font.family'] = 'Malgun Gothic'
        elif system == 'Darwin':
            plt.rcParams['font.family'] = 'AppleGothic'
        else:
            plt.rcParams['font.family'] = 'NanumGothic'
        
        plt.rcParams['axes.unicode_minus'] = False
    
    def detect_file_info(self, file) -> Dict[str, Any]:
        file.seek(0)
        file_info = {
            'name': file.name,
            'size': file.size,
            'type': 'csv' if file.name.endswith('.csv') else 'excel'
        }
        
        if file_info['type'] == 'csv':
            file.seek(0)
            raw_data = file.read(10000)
            file.seek(0)
            result = chardet.detect(raw_data)
            file_info['encoding'] = result['encoding'] or 'utf-8'
        
        return file_info
    
    def get_appropriate_stats(self, main_type: str, sub_type: str) -> List[str]:
        """ë°ì´í„° íƒ€ì…ì— ë”°ë¥¸ ì ì ˆí•œ í†µê³„ ì˜µì…˜ ë°˜í™˜"""
        if main_type == "numeric":
            if sub_type == "continuous":
                return ["ê¸°ìˆ í†µê³„", "ë¶„ìœ„ìˆ˜", "ë¶„í¬íŠ¹ì„±", "ì´ìƒì¹˜"]
            elif sub_type == "discrete":
                return ["ê¸°ìˆ í†µê³„", "ë¹ˆë„ë¶„ì„", "ë¶„í¬íŠ¹ì„±"]
            elif sub_type == "binary":
                return ["ì´ì§„ë¶„í¬", "ë¹„ìœ¨ë¶„ì„"]
        
        elif main_type == "categorical":
            if sub_type == "nominal":
                return ["ë¹ˆë„ë¶„ì„", "ìƒìœ„ì¹´í…Œê³ ë¦¬", "í¬ì†Œì¹´í…Œê³ ë¦¬", "ë¹„ìœ¨ë¶„ì„", "ì—”íŠ¸ë¡œí”¼"]  # ğŸ”´ ì¶”ê°€
            elif sub_type == "ordinal":
                return ["ë¹ˆë„ë¶„ì„", "ìƒìœ„ì¹´í…Œê³ ë¦¬", "ìˆœì„œí†µê³„", "ë¹„ìœ¨ë¶„ì„", "ì—”íŠ¸ë¡œí”¼"]  # ğŸ”´ ì¶”ê°€
            elif sub_type == "binary":
                return ["ì´ì§„ë¶„í¬", "ë¹„ìœ¨ë¶„ì„", "ì—”íŠ¸ë¡œí”¼"]  # ğŸ”´ ì¶”ê°€
        
        elif main_type == "text":
            if sub_type == "short":
                return ["ë¹ˆë„ë¶„ì„", "í…ìŠ¤íŠ¸í†µê³„", "íŒ¨í„´ë¶„ì„", "ì—”íŠ¸ë¡œí”¼"]  # ğŸ”´ ì¶”ê°€
            elif sub_type == "long":
                return ["í…ìŠ¤íŠ¸í†µê³„", "íŒ¨í„´ë¶„ì„", "ë‹¨ì–´í†µê³„"]
        
        elif main_type == "datetime":
            return ["ì‹œê°„ë²”ìœ„", "ì£¼ê¸°ë¶„ì„", "ì‹œê°„ê°„ê²©í†µê³„"]
        
        return []
    
    def get_appropriate_visualizations(self, main_type: str, sub_type: str) -> List[str]:
        """ë°ì´í„° íƒ€ì…ì— ë”°ë¥¸ ì ì ˆí•œ ì‹œê°í™” ì˜µì…˜ ë°˜í™˜"""
        if main_type == "numeric":
            if sub_type == "continuous":
                return ["íˆìŠ¤í† ê·¸ë¨", "ë°•ìŠ¤í”Œë¡¯", "ë°€ë„í”Œë¡¯", "ë°”ì´ì˜¬ë¦°í”Œë¡¯", "ì‚°ì ë„"]
            elif sub_type == "discrete":
                return ["ë§‰ëŒ€ê·¸ë˜í”„", "íˆìŠ¤í† ê·¸ë¨", "íŒŒì´ì°¨íŠ¸", "ìƒìœ„Në§‰ëŒ€ê·¸ë˜í”„", "ì‚°ì ë„"]
            elif sub_type == "binary":
                return ["íŒŒì´ì°¨íŠ¸", "ë§‰ëŒ€ê·¸ë˜í”„", "ë„ë„›ì°¨íŠ¸"]
        
        elif main_type == "categorical":
            if sub_type == "nominal" or sub_type == "ordinal":
                return ["ë§‰ëŒ€ê·¸ë˜í”„", "íŒŒì´ì°¨íŠ¸", "ê°€ë¡œë§‰ëŒ€ê·¸ë˜í”„", "ìƒìœ„Në§‰ëŒ€ê·¸ë˜í”„", "íŒŒë ˆí† ì°¨íŠ¸"]
            elif sub_type == "binary":
                return ["íŒŒì´ì°¨íŠ¸", "ë§‰ëŒ€ê·¸ë˜í”„", "ë„ë„›ì°¨íŠ¸"]
        
        elif main_type == "text":
            if sub_type == "short":
                return ["ìƒìœ„Në§‰ëŒ€ê·¸ë˜í”„", "ë‹¨ì–´ë¹ˆë„", "ê°€ë¡œë§‰ëŒ€ê·¸ë˜í”„"]
            elif sub_type == "long":
                return ["ê¸¸ì´ë¶„í¬", "ë‹¨ì–´ë¹ˆë„", "ìƒìœ„Në§‰ëŒ€ê·¸ë˜í”„"]
        
        elif main_type == "datetime":
            return ["ì‹œê³„ì—´ê·¸ë˜í”„", "ì›”ë³„ë¶„í¬", "ìš”ì¼ë¶„í¬", "ì‹œê°„ëŒ€ë¶„í¬", "ì‚°ì ë„"]
        
        return ["ë§‰ëŒ€ê·¸ë˜í”„"]
    
    def calculate_statistics(self, df: pd.DataFrame, column: str, stat_type: str) -> Dict:
        """ì„ íƒëœ í†µê³„ ê³„ì‚°"""
        col_data = df[column].dropna()
        
        # ê¸°ë³¸ì •ë³´
        if stat_type == "ê¸°ë³¸ì •ë³´":
            return {
                'ì „ì²´ ê°œìˆ˜': f"{len(df[column]):,}",
                'ê²°ì¸¡ê°’': f"{df[column].isnull().sum():,}",
                'ê²°ì¸¡ê°’ ë¹„ìœ¨': f"{df[column].isnull().sum()/len(df[column])*100:.1f}%",
                'ê³ ìœ ê°’': f"{df[column].nunique():,}"
            }
        
        # ê¸°ìˆ í†µê³„
        elif stat_type == "ê¸°ìˆ í†µê³„":
            return {
                'ê°œìˆ˜': f"{len(col_data):,}",
                'í‰ê· ': f"{col_data.mean():.4f}",
                'í‘œì¤€í¸ì°¨': f"{col_data.std():.4f}",
                'ìµœì†Œê°’': f"{col_data.min():.4f}",
                'ìµœëŒ€ê°’': f"{col_data.max():.4f}",
                'ì¤‘ì•™ê°’': f"{col_data.median():.4f}"
            }
        
        # ë¶„ìœ„ìˆ˜
        elif stat_type == "ë¶„ìœ„ìˆ˜":
            return {
                '10%': f"{col_data.quantile(0.10):.4f}",
                '25%': f"{col_data.quantile(0.25):.4f}",
                '50%': f"{col_data.quantile(0.50):.4f}",
                '75%': f"{col_data.quantile(0.75):.4f}",
                '90%': f"{col_data.quantile(0.90):.4f}"
            }
        
        # ë¶„í¬íŠ¹ì„±
        elif stat_type == "ë¶„í¬íŠ¹ì„±":
            from scipy import stats
            return {
                'ì™œë„': f"{col_data.skew():.4f}",
                'ì²¨ë„': f"{col_data.kurtosis():.4f}",
                'ë³€ë™ê³„ìˆ˜': f"{(col_data.std() / col_data.mean()):.4f}" if col_data.mean() != 0 else "N/A"
            }
        
        # ì´ìƒì¹˜
        elif stat_type == "ì´ìƒì¹˜":
            Q1 = col_data.quantile(0.25)
            Q3 = col_data.quantile(0.75)
            IQR = Q3 - Q1
            outliers = col_data[(col_data < Q1 - 1.5 * IQR) | (col_data > Q3 + 1.5 * IQR)]
            return {
                'IQR': f"{IQR:.4f}",
                'í•˜í•œ': f"{Q1 - 1.5 * IQR:.4f}",
                'ìƒí•œ': f"{Q3 + 1.5 * IQR:.4f}",
                'ì´ìƒì¹˜ ê°œìˆ˜': f"{len(outliers):,}",
                'ì´ìƒì¹˜ ë¹„ìœ¨': f"{len(outliers)/len(col_data)*100:.2f}%"
            }
        
        # ë¹ˆë„ë¶„ì„
        elif stat_type == "ë¹ˆë„ë¶„ì„":
            value_counts = df[column].value_counts()
            
            # 20ê°œ ì´ìƒì¼ ë•Œ DataFrameìœ¼ë¡œ ë°˜í™˜í•˜ì—¬ ìë™ ìŠ¤í¬ë¡¤
            if len(value_counts) > 20:
                freq_df = pd.DataFrame({
                    'ê°’': value_counts.index,
                    'ë¹ˆë„': value_counts.values,
                    'ë¹„ìœ¨(%)': (value_counts.values / len(df) * 100).round(2)
                })
                return freq_df  # DataFrameì€ ìë™ìœ¼ë¡œ ìŠ¤í¬ë¡¤ ì²˜ë¦¬ë¨
            else:
                return value_counts.to_dict()
        

            # ğŸ”´ ì—”íŠ¸ë¡œí”¼ í†µê³„ ì¶”ê°€ (ë¹ˆë„ë¶„ì„ ë‹¤ìŒì— ì¶”ê°€)
        elif stat_type == "ì—”íŠ¸ë¡œí”¼":
            value_counts = col_data.value_counts()
            
            if len(value_counts) > 0:
                # í™•ë¥  ê³„ì‚°
                probabilities = value_counts / len(col_data)
                
                # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°: H = -Î£ p_i * log2(p_i)
                entropy = 0
                for p in probabilities:
                    if p > 0:  # log(0) ë°©ì§€
                        entropy -= p * np.log2(p)
                
                # ìµœëŒ€ ì—”íŠ¸ë¡œí”¼ (ëª¨ë“  ê°’ì´ ë™ì¼ í™•ë¥ ì¼ ë•Œ)
                max_entropy = np.log2(len(value_counts))
                
                # ì •ê·œí™”ëœ ì—”íŠ¸ë¡œí”¼ (0~1 ë²”ìœ„)
                normalized_entropy = entropy / max_entropy if max_entropy > 0 else 0
                
                return {
                    'ì—”íŠ¸ë¡œí”¼ (H)': f"{entropy:.4f} bits",
                    'ìµœëŒ€ ê°€ëŠ¥ ì—”íŠ¸ë¡œí”¼': f"{max_entropy:.4f} bits",
                    'ì •ê·œí™” ì—”íŠ¸ë¡œí”¼': f"{normalized_entropy:.4f}",
                    'ê³ ìœ ê°’ ìˆ˜': f"{len(value_counts)}ê°œ",
                    'í•´ì„': self._interpret_entropy(normalized_entropy)
                }
            else:
                return {'ì˜¤ë¥˜': 'ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}
    

    
        # ìƒìœ„ì¹´í…Œê³ ë¦¬
        elif stat_type == "ìƒìœ„ì¹´í…Œê³ ë¦¬":
            value_counts = col_data.value_counts()
            total = len(col_data)
            top10 = value_counts.head(10)
            result = {}
            for val, count in top10.items():
                result[f"{str(val)[:30]}"] = f"{count:,} ({count/total*100:.1f}%)"
            result['ìƒìœ„ 10ê°œ í•©ê³„'] = f"{top10.sum():,} ({top10.sum()/total*100:.1f}%)"
            return result
        
        # í¬ì†Œì¹´í…Œê³ ë¦¬
        elif stat_type == "í¬ì†Œì¹´í…Œê³ ë¦¬":
            value_counts = col_data.value_counts()
            rare = value_counts[value_counts <= 5]
            return {
                'í¬ì†Œê°’ ê°œìˆ˜': f"{len(rare)}ê°œ",
                '1íšŒ ì¶œí˜„': f"{(value_counts == 1).sum()}ê°œ",
                '5íšŒ ì´í•˜': f"{len(rare)}ê°œ",
                'í¬ì†Œê°’ ë¹„ìœ¨': f"{len(rare)/len(value_counts)*100:.1f}%"
            }
        
        # ì´ì§„ë¶„í¬
        elif stat_type == "ì´ì§„ë¶„í¬":
            value_counts = col_data.value_counts()
            if len(value_counts) >= 2:
                val1, val2 = value_counts.index[:2]
                return {
                    f'{val1}': f"{value_counts[val1]:,} ({value_counts[val1]/len(col_data)*100:.1f}%)",
                    f'{val2}': f"{value_counts.get(val2, 0):,} ({value_counts.get(val2, 0)/len(col_data)*100:.1f}%)"
                }
            else:
                return {'ê²°ê³¼': 'ì´ì§„ ë°ì´í„°ê°€ ì•„ë‹™ë‹ˆë‹¤'}
        
        # ë¹„ìœ¨ë¶„ì„
        elif stat_type == "ë¹„ìœ¨ë¶„ì„":
            value_counts = col_data.value_counts()
            return {
                'ìµœë¹ˆê°’': f"{value_counts.index[0]}",
                'ìµœë¹ˆê°’ ë¹„ìœ¨': f"{value_counts.iloc[0]/len(col_data)*100:.1f}%",
                'ê³ ìœ ê°’ ìˆ˜': f"{len(value_counts)}ê°œ"
            }
        
        # ìˆœì„œí†µê³„
        elif stat_type == "ìˆœì„œí†µê³„":
            try:
                # ìˆœì„œí˜• ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ë³€í™˜ ì‹œë„
                numeric_data = pd.to_numeric(col_data, errors='coerce').dropna()
                if len(numeric_data) > 0:
                    return {
                        'ìµœì†Œê°’': f"{numeric_data.min():.0f}",
                        'ìµœëŒ€ê°’': f"{numeric_data.max():.0f}",
                        'ì¤‘ì•™ê°’': f"{numeric_data.median():.0f}",
                        'ë²”ìœ„': f"{numeric_data.max() - numeric_data.min():.0f}"
                    }
            except:
                pass
            
            # ìˆ«ì ë³€í™˜ ì‹¤íŒ¨ì‹œ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
            sorted_values = sorted(col_data.unique())
            return {
                'ìµœì†Œê°’': str(sorted_values[0]),
                'ìµœëŒ€ê°’': str(sorted_values[-1]),
                'ê³ ìœ ê°’ ìˆ˜': f"{len(sorted_values)}ê°œ"
            }
        
        # í…ìŠ¤íŠ¸í†µê³„
        elif stat_type == "í…ìŠ¤íŠ¸í†µê³„":
            text_series = col_data.astype(str)
            lengths = text_series.str.len()
            return {
                'í‰ê·  ê¸¸ì´': f"{lengths.mean():.1f}",
                'ìµœëŒ€ ê¸¸ì´': f"{lengths.max()}",
                'ìµœì†Œ ê¸¸ì´': f"{lengths.min()}",
                'ê¸¸ì´ í‘œì¤€í¸ì°¨': f"{lengths.std():.1f}"
            }
        
        # íŒ¨í„´ë¶„ì„
        elif stat_type == "íŒ¨í„´ë¶„ì„":
            text_series = col_data.astype(str)
            return {
                'ìˆ«ì í¬í•¨': f"{text_series.str.contains(r'\d', na=False).sum():,}ê°œ",
                'ì˜ë¬¸ í¬í•¨': f"{text_series.str.contains(r'[a-zA-Z]', na=False).sum():,}ê°œ",
                'í•œê¸€ í¬í•¨': f"{text_series.str.contains(r'[ê°€-í£]', na=False).sum():,}ê°œ",
                'íŠ¹ìˆ˜ë¬¸ì í¬í•¨': f"{text_series.str.contains(r'[^a-zA-Z0-9ê°€-í£\s]', na=False).sum():,}ê°œ"
            }
        
        # ë‹¨ì–´í†µê³„
        elif stat_type == "ë‹¨ì–´í†µê³„":
            text_series = col_data.astype(str)
            word_counts = text_series.str.split().str.len()
            return {
                'í‰ê·  ë‹¨ì–´ ìˆ˜': f"{word_counts.mean():.1f}",
                'ìµœëŒ€ ë‹¨ì–´ ìˆ˜': f"{word_counts.max()}",
                'ìµœì†Œ ë‹¨ì–´ ìˆ˜': f"{word_counts.min()}",
                'ì´ ë‹¨ì–´ ìˆ˜': f"{word_counts.sum():,}"
            }
        
        # ì‹œê°„ë²”ìœ„
        elif stat_type == "ì‹œê°„ë²”ìœ„":
            try:
                datetime_data = pd.to_datetime(col_data)
                return {
                    'ì‹œì‘ì¼': str(datetime_data.min()),
                    'ì¢…ë£Œì¼': str(datetime_data.max()),
                    'ê¸°ê°„': str(datetime_data.max() - datetime_data.min()),
                    'ê³ ìœ ì¼ìˆ˜': f"{datetime_data.dt.date.nunique():,}"
                }
            except:
                return {'ì˜¤ë¥˜': 'ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì‹¤íŒ¨'}
        
        # ì£¼ê¸°ë¶„ì„
        elif stat_type == "ì£¼ê¸°ë¶„ì„":
            try:
                datetime_data = pd.to_datetime(col_data)
                return {
                    'ìµœë¹ˆ ìš”ì¼': datetime_data.dt.day_name().mode()[0] if not datetime_data.dt.day_name().mode().empty else "N/A",
                    'ìµœë¹ˆ ì›”': f"{datetime_data.dt.month.mode()[0]}ì›”" if not datetime_data.dt.month.mode().empty else "N/A",
                    'ì£¼ë§ ë¹„ìœ¨': f"{(datetime_data.dt.dayofweek >= 5).sum() / len(datetime_data) * 100:.1f}%"
                }
            except:
                return {'ì˜¤ë¥˜': 'ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì‹¤íŒ¨'}
        
        # ì‹œê°„ê°„ê²©í†µê³„
        elif stat_type == "ì‹œê°„ê°„ê²©í†µê³„":
            try:
                datetime_data = pd.to_datetime(col_data).sort_values()
                intervals = datetime_data.diff().dropna()
                return {
                    'í‰ê·  ê°„ê²©': str(intervals.mean()),
                    'ìµœì†Œ ê°„ê²©': str(intervals.min()),
                    'ìµœëŒ€ ê°„ê²©': str(intervals.max()),
                    'ê°„ê²© í‘œì¤€í¸ì°¨': str(intervals.std())
                }
            except:
                return {'ì˜¤ë¥˜': 'ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì‹¤íŒ¨'}
        
        return {'ì˜¤ë¥˜': 'ì•Œ ìˆ˜ ì—†ëŠ” í†µê³„ íƒ€ì…'}
    
    def create_visualization(self, df: pd.DataFrame, column: str, viz_type: str, params: Dict) -> plt.Figure:
        """ì„ íƒëœ ì‹œê°í™” ìƒì„±"""
        col_data = df[column].dropna()
        
        # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì‘ê²Œ ì¡°ì •
        fig, ax = plt.subplots(figsize=(6, 4))
        
        try:
            # íˆìŠ¤í† ê·¸ë¨
            if viz_type == "íˆìŠ¤í† ê·¸ë¨":
                bins = params.get('bins', 30)
                col_data.hist(bins=bins, ax=ax, edgecolor='black', alpha=0.7)
                ax.set_xlabel(column)
                ax.set_ylabel('ë¹ˆë„')
                ax.set_title(f'{column} íˆìŠ¤í† ê·¸ë¨')
            
            # ë°•ìŠ¤í”Œë¡¯
            elif viz_type == "ë°•ìŠ¤í”Œë¡¯":
                ax.boxplot(col_data, vert=True, patch_artist=True,
                          boxprops=dict(facecolor='lightblue', alpha=0.7))
                ax.set_ylabel(column)
                ax.set_title(f'{column} ë°•ìŠ¤í”Œë¡¯')
            
            # ë°€ë„í”Œë¡¯
            elif viz_type == "ë°€ë„í”Œë¡¯":
                col_data.plot.density(ax=ax, color='blue')
                ax.set_xlabel(column)
                ax.set_ylabel('ë°€ë„')
                ax.set_title(f'{column} ë°€ë„í”Œë¡¯')
            
            # ë°”ì´ì˜¬ë¦°í”Œë¡¯
            elif viz_type == "ë°”ì´ì˜¬ë¦°í”Œë¡¯":
                parts = ax.violinplot([col_data], positions=[1], showmeans=True, showmedians=True)
                ax.set_xticks([1])
                ax.set_xticklabels([column])
                ax.set_ylabel('ê°’')
                ax.set_title(f'{column} ë°”ì´ì˜¬ë¦°í”Œë¡¯')
            
                # ì‚°ì ë„ ìˆ˜ì •
            elif viz_type == "ì‚°ì ë„":
                if 'other_column' in params:
                    other_col = params['other_column']
                    
                    # ë‘ ì—´ì˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì „ì²˜ë¦¬ëœ ë°ì´í„° ìš°ì„  ì‚¬ìš©)
                    if hasattr(self, 'get_processed_data'):
                        x_data = self.get_processed_data(df, column)
                        y_data = self.get_processed_data(df, other_col)
                    else:
                        x_data = df[column]
                        y_data = df[other_col]
                    
                    # ê²°ì¸¡ê°’ ì œê±°
                    valid_idx = x_data.notna() & y_data.notna()
                    x_data = x_data[valid_idx]
                    y_data = y_data[valid_idx]
                    
                    ax.scatter(x_data, y_data, alpha=0.6, s=30)
                    ax.set_xlabel(column)
                    ax.set_ylabel(other_col)
                    ax.set_title(f'{column} vs {other_col} ì‚°ì ë„')
                    
                    # ìƒê´€ê³„ìˆ˜ í‘œì‹œ
                    if len(x_data) > 1:
                        corr = x_data.corr(y_data)
                        ax.text(0.05, 0.95, f'ìƒê´€ê³„ìˆ˜: {corr:.3f}', 
                            transform=ax.transAxes, 
                            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
                    
                    # íšŒê·€ì„  ì˜µì…˜
                    if params.get('show_regression', False):
                        z = np.polyfit(x_data, y_data, 1)
                        p = np.poly1d(z)
                        ax.plot(sorted(x_data), p(sorted(x_data)), "r--", alpha=0.8, linewidth=2)
                else:
                    # ì¸ë±ìŠ¤ë¥¼ xì¶•ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ì‚°ì ë„
                    ax.scatter(range(len(col_data)), col_data, alpha=0.6, s=30)
                    ax.set_xlabel('ì¸ë±ìŠ¤')
                    ax.set_ylabel(column)
                    ax.set_title(f'{column} ì‚°ì ë„')

            
            # ë§‰ëŒ€ê·¸ë˜í”„
            elif viz_type == "ë§‰ëŒ€ê·¸ë˜í”„":
                value_counts = col_data.value_counts()
                if len(value_counts) > 30:
                    value_counts = value_counts.head(30)
                value_counts.plot(kind='bar', ax=ax, color='skyblue', edgecolor='black')
                ax.set_xlabel(column)
                ax.set_ylabel('ë¹ˆë„')
                ax.set_title(f'{column} ë§‰ëŒ€ê·¸ë˜í”„')
                plt.xticks(rotation=45, ha='right')
            
            # ê°€ë¡œë§‰ëŒ€ê·¸ë˜í”„
            elif viz_type == "ê°€ë¡œë§‰ëŒ€ê·¸ë˜í”„":
                value_counts = col_data.value_counts()
                if len(value_counts) > 30:
                    value_counts = value_counts.head(30)
                value_counts.plot(kind='barh', ax=ax, color='lightgreen', edgecolor='black')
                ax.set_xlabel('ë¹ˆë„')
                ax.set_ylabel(column)
                ax.set_title(f'{column} ê°€ë¡œë§‰ëŒ€ê·¸ë˜í”„')
            
            # ìƒìœ„Në§‰ëŒ€ê·¸ë˜í”„
            elif viz_type == "ìƒìœ„Në§‰ëŒ€ê·¸ë˜í”„":
                top_n = params.get('top_n', 20)
                value_counts = col_data.value_counts().head(top_n)
                value_counts.plot(kind='bar', ax=ax, color='coral', edgecolor='black')
                ax.set_xlabel(column)
                ax.set_ylabel('ë¹ˆë„')
                ax.set_title(f'{column} ìƒìœ„ {top_n}ê°œ')
                plt.xticks(rotation=45, ha='right')
            
            # íŒŒì´ì°¨íŠ¸
            elif viz_type == "íŒŒì´ì°¨íŠ¸":
                value_counts = col_data.value_counts()
                if len(value_counts) > 10:
                    value_counts = value_counts.head(10)
                ax.pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%', startangle=90)
                ax.set_title(f'{column} íŒŒì´ì°¨íŠ¸')
            
            # ë„ë„›ì°¨íŠ¸
            elif viz_type == "ë„ë„›ì°¨íŠ¸":
                value_counts = col_data.value_counts()
                if len(value_counts) > 10:
                    value_counts = value_counts.head(10)
                wedges, texts, autotexts = ax.pie(value_counts.values, labels=value_counts.index, 
                                                  autopct='%1.1f%%', startangle=90)
                centre_circle = plt.Circle((0,0), 0.70, fc='white')
                ax.add_artist(centre_circle)
                ax.set_title(f'{column} ë„ë„›ì°¨íŠ¸')
            
            # íŒŒë ˆí† ì°¨íŠ¸
            elif viz_type == "íŒŒë ˆí† ì°¨íŠ¸":
                top_n = params.get('top_n', 20)
                value_counts = col_data.value_counts().head(top_n)
                cumsum = value_counts.cumsum() / value_counts.sum() * 100
                
                ax.bar(range(len(value_counts)), value_counts.values, color='skyblue', edgecolor='black')
                ax.set_ylabel('ë¹ˆë„', color='blue')
                
                ax2 = ax.twinx()
                ax2.plot(range(len(value_counts)), cumsum.values, 'ro-', linewidth=2)
                ax2.set_ylabel('ëˆ„ì  ë¹„ìœ¨ (%)', color='red')
                ax2.set_ylim(0, 105)
                
                ax.set_xticks(range(len(value_counts)))
                ax.set_xticklabels([str(x)[:15] for x in value_counts.index], rotation=45, ha='right')
                ax.set_title(f'{column} íŒŒë ˆí† ì°¨íŠ¸')
            
            # ë‹¨ì–´ë¹ˆë„
            elif viz_type == "ë‹¨ì–´ë¹ˆë„":
                words = ' '.join(col_data.astype(str)).split()
                word_freq = pd.Series(words).value_counts().head(20)
                word_freq.plot(kind='bar', ax=ax, color='purple', edgecolor='black')
                ax.set_xlabel('ë‹¨ì–´')
                ax.set_ylabel('ë¹ˆë„')
                ax.set_title(f'{column} ë‹¨ì–´ ë¹ˆë„ (ìƒìœ„ 20ê°œ)')
                plt.xticks(rotation=45, ha='right')
            
            # ê¸¸ì´ë¶„í¬
            elif viz_type == "ê¸¸ì´ë¶„í¬":
                lengths = col_data.astype(str).str.len()
                lengths.hist(bins=30, ax=ax, edgecolor='black', color='green', alpha=0.7)
                ax.set_xlabel('ë¬¸ìì—´ ê¸¸ì´')
                ax.set_ylabel('ë¹ˆë„')
                ax.set_title(f'{column} ë¬¸ìì—´ ê¸¸ì´ ë¶„í¬')
            
            # ì‹œê³„ì—´ê·¸ë˜í”„
            elif viz_type == "ì‹œê³„ì—´ê·¸ë˜í”„":
                try:
                    datetime_data = pd.to_datetime(col_data)
                    datetime_data.value_counts().sort_index().plot(ax=ax, color='navy')
                    ax.set_xlabel('ë‚ ì§œ')
                    ax.set_ylabel('ë¹ˆë„')
                    ax.set_title(f'{column} ì‹œê³„ì—´ ë¶„í¬')
                    plt.xticks(rotation=45)
                except:
                    ax.text(0.5, 0.5, 'ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì‹¤íŒ¨', ha='center', va='center')
            
            # ì›”ë³„ë¶„í¬
            elif viz_type == "ì›”ë³„ë¶„í¬":
                try:
                    datetime_data = pd.to_datetime(col_data)
                    month_counts = datetime_data.dt.month.value_counts().sort_index()
                    month_counts.plot(kind='bar', ax=ax, color='orange')
                    ax.set_xlabel('ì›”')
                    ax.set_ylabel('ë¹ˆë„')
                    ax.set_title(f'{column} ì›”ë³„ ë¶„í¬')
                    ax.set_xticklabels([f'{i}ì›”' for i in month_counts.index])
                except:
                    ax.text(0.5, 0.5, 'ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì‹¤íŒ¨', ha='center', va='center')
            
            # ìš”ì¼ë¶„í¬
            elif viz_type == "ìš”ì¼ë¶„í¬":
                try:
                    datetime_data = pd.to_datetime(col_data)
                    weekday_counts = datetime_data.dt.dayofweek.value_counts().sort_index()
                    weekday_names = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
                    weekday_counts.plot(kind='bar', ax=ax, color='teal')
                    ax.set_xlabel('ìš”ì¼')
                    ax.set_ylabel('ë¹ˆë„')
                    ax.set_title(f'{column} ìš”ì¼ë³„ ë¶„í¬')
                    ax.set_xticklabels([weekday_names[i] for i in weekday_counts.index])
                except:
                    ax.text(0.5, 0.5, 'ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì‹¤íŒ¨', ha='center', va='center')
            
            # ì‹œê°„ëŒ€ë¶„í¬
            elif viz_type == "ì‹œê°„ëŒ€ë¶„í¬":
                try:
                    datetime_data = pd.to_datetime(col_data)
                    hour_counts = datetime_data.dt.hour.value_counts().sort_index()
                    hour_counts.plot(kind='bar', ax=ax, color='brown')
                    ax.set_xlabel('ì‹œê°„')
                    ax.set_ylabel('ë¹ˆë„')
                    ax.set_title(f'{column} ì‹œê°„ëŒ€ë³„ ë¶„í¬')
                    ax.set_xticklabels([f'{i}ì‹œ' for i in hour_counts.index])
                except:
                    ax.text(0.5, 0.5, 'ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì‹¤íŒ¨', ha='center', va='center')
            
        except Exception as e:
            plt.close(fig)
            raise Exception(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {str(e)}")
        
        plt.tight_layout()
        return fig
    
    def create_dtype_distribution_chart(self, df: pd.DataFrame):
        """ë°ì´í„° íƒ€ì… ë¶„í¬ ì°¨íŠ¸ ìƒì„±"""
        dtype_counts = df.dtypes.value_counts()
        
        fig, ax = plt.subplots(figsize=(8, 4))
        colors = plt.cm.Set3(range(len(dtype_counts)))
        bars = dtype_counts.plot(kind='bar', ax=ax, color=colors, edgecolor='black')
        
        # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
        for i, (index, value) in enumerate(dtype_counts.items()):
            ax.text(i, value + 0.1, str(value), ha='center', va='bottom')
        
        ax.set_title("ì—´ë³„ ë°ì´í„° íƒ€ì… ë¶„í¬")
        ax.set_xlabel("ë°ì´í„° íƒ€ì…")
        ax.set_ylabel("ê°œìˆ˜")
        plt.xticks(rotation=45)
        plt.tight_layout()
        
        return fig
    
    def _interpret_entropy(self, normalized_entropy: float) -> str:
        """ì •ê·œí™”ëœ ì—”íŠ¸ë¡œí”¼ ê°’ í•´ì„"""
        if normalized_entropy < 0.3:
            return "ë§¤ìš° ë‚®ìŒ (ë°ì´í„°ê°€ íŠ¹ì • ê°’ì— ì§‘ì¤‘)"
        elif normalized_entropy < 0.5:
            return "ë‚®ìŒ (ì¼ë¶€ ê°’ì´ ìš°ì„¸)"
        elif normalized_entropy < 0.7:
            return "ì¤‘ê°„ (ì ë‹¹í•œ ë‹¤ì–‘ì„±)"
        elif normalized_entropy < 0.9:
            return "ë†’ìŒ (ê°’ì´ ê³ ë¥´ê²Œ ë¶„í¬)"
        else:
            return "ë§¤ìš° ë†’ìŒ (ê±°ì˜ ê· ë“± ë¶„í¬)"
