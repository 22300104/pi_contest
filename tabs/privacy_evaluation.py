# privacy_evaluation.py (ê°œì„  ë²„ì „)

import streamlit as st
import pandas as pd
import numpy as np
from typing import List, Dict, Tuple, Any
import matplotlib.pyplot as plt
import json, uuid, time

# k-ìµëª…ì„± ê³„ì‚°ì„ ìœ„í•œ ìƒˆë¡œìš´ ëª¨ë“ˆë„ í•„ìš”í•©ë‹ˆë‹¤
try:
    from modules.privacy_metrics.k_anonymity import KAnonymityAnalyzer
except ImportError:
    # ëª¨ë“ˆì´ ì•„ì§ ì—†ìœ¼ë©´ ì„ì‹œë¡œ ì²˜ë¦¬
    pass

def get_column_types():
    """ì „ì—­ ì„¤ì •ëœ ì»¬ëŸ¼ íƒ€ì… ë°˜í™˜"""
    return {
        'numeric': st.session_state.get('global_numeric_cols', []),
        'categorical': st.session_state.get('global_categorical_cols', []),
        'datetime': st.session_state.get('global_datetime_cols', [])
    }

def render_privacy_evaluation_tab():
    """í”„ë¼ì´ë²„ì‹œ í‰ê°€ íƒ­ ë Œë”ë§"""
    st.header("ğŸ“‹ í”„ë¼ì´ë²„ì‹œ í‰ê°€")
    
    if "df" not in st.session_state or st.session_state.df is None:
        st.warning("ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return
    
    # ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©, ì—†ìœ¼ë©´ ì›ë³¸ ì‚¬ìš©
    df = st.session_state.get("df_processed", st.session_state.df)
    
    # íƒ­ ìƒì„±
    tab1, tab2 = st.tabs(["ğŸ“Š k-ìµëª…ì„± ë¶„ì„", "ğŸ“ˆ ìœ ìš©ì„± í‰ê°€"])
    
    with tab1:
        render_k_anonymity_section(df)
    
    with tab2:
        render_utility_evaluation_section(df)

def render_k_anonymity_section(df: pd.DataFrame):
    """k-ìµëª…ì„± ë¶„ì„ ì„¹ì…˜"""
    st.subheader("ğŸ“Š k-ìµëª…ì„± ë¶„ì„")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # ì¤€ì‹ë³„ì ì„ íƒ
        st.markdown("### ì¤€ì‹ë³„ì ì„ íƒ")
        st.info("ì¤€ì‹ë³„ì(Quasi-Identifier)ëŠ” ë‹¨ë…ìœ¼ë¡œëŠ” ê°œì¸ì„ ì‹ë³„í•  ìˆ˜ ì—†ì§€ë§Œ, ì¡°í•©í•˜ë©´ ê°œì¸ì„ ì‹ë³„í•  ê°€ëŠ¥ì„±ì´ ìˆëŠ” ì†ì„±ë“¤ì…ë‹ˆë‹¤.")
        
        # ì»¬ëŸ¼ íƒ€ì…ë³„ë¡œ ë¶„ë¥˜
        numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
        
        # ì¤€ì‹ë³„ì ì„ íƒ UI
        selected_qi = []
        
        if categorical_cols:
            st.markdown("**ë²”ì£¼í˜• ì†ì„±**")
            cat_selected = st.multiselect(
                "ë²”ì£¼í˜• ì¤€ì‹ë³„ì ì„ íƒ",
                categorical_cols,
                help="ì˜ˆ: ì„±ë³„, ì§€ì—­, ì§ì—… ë“±",
                key="cat_qi_select"
            )
            selected_qi.extend(cat_selected)
        
        if numeric_cols:
            st.markdown("**ìˆ˜ì¹˜í˜• ì†ì„±**")
            num_selected = st.multiselect(
                "ìˆ˜ì¹˜í˜• ì¤€ì‹ë³„ì ì„ íƒ",
                numeric_cols,
                help="ì˜ˆ: ë‚˜ì´, ìš°í¸ë²ˆí˜¸ ë“±",
                key="num_qi_select"
            )
            selected_qi.extend(num_selected)
    
    with col2:
        # ë¶„ì„ ì˜µì…˜
        st.markdown("### ë¶„ì„ ì˜µì…˜")
        
        # ğŸ”´ í‘œë³¸ë¥  ì…ë ¥ ì¶”ê°€
        st.markdown("#### ğŸ“Š í‘œë³¸ë¥  ì„¤ì •")
        sample_rate = st.number_input(
            "í‘œë³¸ë¥  (f)",
            min_value=0.001,
            max_value=1.0,
            value=1.0,
            step=0.01,
            format="%.3f",
            help="ì „ì²´ ëª¨ì§‘ë‹¨ ëŒ€ë¹„ í˜„ì¬ ë°ì´í„°ì˜ ë¹„ìœ¨ (1.0 = ì „ì²´ ë°ì´í„°)"
        )
        
        # í‘œë³¸ë¥ ì— ë”°ë¥¸ ì„¤ëª…
        if sample_rate < 1.0:
            st.info(f"ğŸ“Œ í˜„ì¬ ë°ì´í„°ëŠ” ì „ì²´ ëª¨ì§‘ë‹¨ì˜ {sample_rate*100:.1f}%ì…ë‹ˆë‹¤")
        else:
            st.info("ğŸ“Œ ì „ì²´ ëª¨ì§‘ë‹¨ ë°ì´í„°ë¡œ ë¶„ì„í•©ë‹ˆë‹¤")
        
            # ğŸ”´ í‘œë³¸ë¥  ì…ë ¥ ì¶”ê°€
    st.markdown("#### ğŸ“Š í‘œë³¸ë¥  ì„¤ì •")
    sample_rate = st.number_input(
        "í‘œë³¸ë¥  (f)",
        min_value=0.001,
        max_value=1.0,
        value=1.0,
        step=0.01,
        format="%.3f",
        help="ì „ì²´ ëª¨ì§‘ë‹¨ ëŒ€ë¹„ í˜„ì¬ ë°ì´í„°ì˜ ë¹„ìœ¨ (1.0 = ì „ì²´ ë°ì´í„°)"
    )
    
    # í‘œë³¸ë¥ ì— ë”°ë¥¸ ì„¤ëª…
    if sample_rate < 1.0:
        st.info(f"ğŸ“Œ í˜„ì¬ ë°ì´í„°ëŠ” ì „ì²´ ëª¨ì§‘ë‹¨ì˜ {sample_rate*100:.1f}%ì…ë‹ˆë‹¤")
    else:
        st.info("ğŸ“Œ ì „ì²´ ëª¨ì§‘ë‹¨ ë°ì´í„°ë¡œ ë¶„ì„í•©ë‹ˆë‹¤")
        # ìƒ˜í”Œë§ ì˜µì…˜ (ëŒ€ìš©ëŸ‰ ë°ì´í„° ëŒ€ì‘)
        data_size = len(df)
        if data_size > 100000:
            use_sampling = st.checkbox(
                "ìƒ˜í”Œë§ ì‚¬ìš©",
                value=True,
                help=f"ì „ì²´ {data_size:,}í–‰ ì¤‘ ì¼ë¶€ë§Œ ë¶„ì„í•˜ì—¬ ì†ë„ í–¥ìƒ"
            )
            if use_sampling:
                sample_size = st.slider(
                    "ìƒ˜í”Œ í¬ê¸°",
                    min_value=10000,
                    max_value=min(100000, data_size),
                    value=50000,
                    step=10000,
                    format="%dí–‰"
                )
        else:
            use_sampling = False
            sample_size = data_size
        
        # kê°’ ì„ê³„ê°’ ì„¤ì •
        k_threshold = st.number_input(
            "kê°’ ì„ê³„ê°’",
            min_value=2,
            max_value=100,
            value=5,
            help="ì´ ê°’ ë¯¸ë§Œì˜ kë¥¼ ê°€ì§„ ë ˆì½”ë“œëŠ” ìœ„í—˜ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤"
        )
    
    # ë™ì§ˆì§‘í•© ë¯¸ë¦¬ë³´ê¸° ì„¹ì…˜
    if selected_qi:  # ì¤€ì‹ë³„ìê°€ ì„ íƒëœ ê²½ìš°
        with st.expander("ğŸ‘¥ ë™ì§ˆì§‘í•© ë¯¸ë¦¬ë³´ê¸°", expanded=False):
            st.info("""
            **ë™ì§ˆì§‘í•©(Equivalence Class)ì´ë€?**
            ì¤€ì‹ë³„ì ê°’ì´ ëª¨ë‘ ë™ì¼í•œ ë ˆì½”ë“œë“¤ì˜ ê·¸ë£¹ì…ë‹ˆë‹¤.
            ì˜ˆ: ë‚˜ì´(30ëŒ€), ì„±ë³„(ë‚¨), ì§€ì—­(ì„œìš¸) â†’ ì´ ì¡°í•©ì´ ê°™ì€ ëª¨ë“  ì‚¬ëŒë“¤
            """)
            
            # ë¯¸ë¦¬ë³´ê¸° ì˜µì…˜
            preview_option = st.radio(
                "ë¯¸ë¦¬ë³´ê¸° ì˜µì…˜",
                ["ìƒìœ„ 5ê°œ ê·¸ë£¹", "kê°’ì´ ë‚®ì€ ìœ„í—˜ ê·¸ë£¹", "ëœë¤ ìƒ˜í”Œ"],
                horizontal=True
            )
            
            # í‘œì‹œí•  ë ˆì½”ë“œ ìˆ˜
            show_records = st.slider("ê·¸ë£¹ë‹¹ í‘œì‹œí•  ë ˆì½”ë“œ ìˆ˜", 1, 10, 3)
            
            if st.button("ë™ì§ˆì§‘í•© í™•ì¸í•˜ê¸°", key="preview_ec_k"):
                with st.spinner("ë™ì§ˆì§‘í•© ë¶„ì„ ì¤‘..."):
                    # ìƒ˜í”Œë§ ì œê±° - dfë¥¼ ì§ì ‘ ì‚¬ìš©
                    preview_df = df
                    
                    # ë™ì§ˆì§‘í•© ìƒì„±
                    ec_groups = preview_df.groupby(selected_qi)
                    
                    # ê° ê·¸ë£¹ì˜ í¬ê¸° ê³„ì‚°
                    ec_sizes = ec_groups.size().reset_index(name='k')
                    
                    if len(ec_sizes) == 0:
                        st.warning("ë™ì§ˆì§‘í•©ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        # ì •ë ¬ ì˜µì…˜ì— ë”°ë¼ ì •ë ¬
                        if preview_option == "kê°’ì´ ë‚®ì€ ìœ„í—˜ ê·¸ë£¹":
                            ec_sizes = ec_sizes.sort_values('k', ascending=True)
                            top_groups = ec_sizes.head(5)
                        elif preview_option == "ìƒìœ„ 5ê°œ ê·¸ë£¹":
                            ec_sizes = ec_sizes.sort_values('k', ascending=False)
                            top_groups = ec_sizes.head(5)
                        else:  # ëœë¤
                            top_groups = ec_sizes.sample(min(5, len(ec_sizes)))
                        
                        # kê°’ ìˆœì„œ ì •ë ¬ ì˜µì…˜ ì¶”ê°€
                        sort_by_k = st.checkbox("kê°’ ìˆœì„œë¡œ ì •ë ¬", value=True, key="sort_by_k")
                        if sort_by_k and preview_option != "ëœë¤ ìƒ˜í”Œ":
                            ascending = preview_option == "kê°’ì´ ë‚®ì€ ìœ„í—˜ ê·¸ë£¹"
                            top_groups = top_groups.sort_values('k', ascending=ascending)
                
                # ê° ê·¸ë£¹ì˜ ìƒ˜í”Œ í‘œì‹œ
                for idx, (_, group_info) in enumerate(top_groups.iterrows()):
                    st.markdown(f"### ê·¸ë£¹ {idx+1}")
                    
                    # ì¤€ì‹ë³„ì ê°’ í‘œì‹œ
                    qi_values = []
                    for qi in selected_qi:
                        if qi in group_info:
                            qi_values.append(f"{qi}: {group_info[qi]}")
                    
                    st.write(f"**ì¤€ì‹ë³„ì ì¡°í•©**: {', '.join(qi_values)}")
                    st.write(f"**kê°’**: {group_info['k']} (ì´ ì¡°í•©ì„ ê°€ì§„ ì‚¬ëŒ ìˆ˜)")
                    
                    # ìœ„í—˜ë„ í‘œì‹œ
                    if group_info['k'] < k_threshold:
                        st.warning(f"âš ï¸ ìœ„í—˜: kê°’ì´ {k_threshold} ë¯¸ë§Œì…ë‹ˆë‹¤!")
                    else:
                        st.success(f"âœ… ì•ˆì „: kê°’ì´ {k_threshold} ì´ìƒì…ë‹ˆë‹¤.")
                    
                    # í•´ë‹¹ ê·¸ë£¹ì˜ ìƒ˜í”Œ ë ˆì½”ë“œ í‘œì‹œ
                    # ì¤€ì‹ë³„ì ê°’ìœ¼ë¡œ í•„í„°ë§
                    mask = True
                    for qi in selected_qi:
                        mask = mask & (preview_df[qi] == group_info[qi])
                    
                    group_records = preview_df[mask].head(show_records)
                    
                    # ë¯¼ê°í•œ ì •ë³´ëŠ” ê°€ë¦¬ê³  í‘œì‹œ
                    display_cols = selected_qi + [col for col in preview_df.columns 
                                            if col not in selected_qi][:3]  # ì¶”ê°€ë¡œ 3ê°œ ì»¬ëŸ¼ë§Œ
                    
                    st.dataframe(
                        group_records[display_cols],
                        use_container_width=True,
                        hide_index=True
                    )
                    
                    st.markdown("---")
                
                # ì „ì²´ í†µê³„
                st.markdown("### ğŸ“Š ì „ì²´ ë™ì§ˆì§‘í•© í†µê³„")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("ì „ì²´ ê·¸ë£¹ ìˆ˜", f"{len(ec_sizes):,}ê°œ")
                with col2:
                    st.metric("í‰ê·  kê°’", f"{ec_sizes['k'].mean():.1f}")
                with col3:
                    risk_groups = len(ec_sizes[ec_sizes['k'] < k_threshold])
                    st.metric("ìœ„í—˜ ê·¸ë£¹", f"{risk_groups}ê°œ")
                
                # kê°’ ë¶„í¬ ê°„ë‹¨íˆ í‘œì‹œ
                st.markdown("#### kê°’ ë¶„í¬")
                k_dist = ec_sizes['k'].value_counts().sort_index()
                
                # ê°„ë‹¨í•œ íˆìŠ¤í† ê·¸ë¨
                hist_data = []
                for k, count in k_dist.items():
                    if k < k_threshold:
                        hist_data.append({
                            'kê°’': f"k={k}",
                            'ê·¸ë£¹ ìˆ˜': count,
                            'ìƒíƒœ': 'ìœ„í—˜'
                        })
                    else:
                        hist_data.append({
                            'kê°’': f"k={k}" if k <= 10 else f"k>{10}",
                            'ê·¸ë£¹ ìˆ˜': count,
                            'ìƒíƒœ': 'ì•ˆì „'
                        })
                
                hist_df = pd.DataFrame(hist_data)
                st.bar_chart(hist_df.set_index('kê°’')['ê·¸ë£¹ ìˆ˜'])
    
    st.markdown("---")
    


    # privacy_evaluation.pyì˜ render_k_anonymity_section í•¨ìˆ˜ ë‚´
    # "ë™ì§ˆì§‘í•© ë¯¸ë¦¬ë³´ê¸°" ì„¹ì…˜ ë‹¤ìŒì— ì¶”ê°€

    with st.expander("ğŸ“Š ECë³„ í†µê³„ ë¶„ì„", expanded=False):
        st.info("""
        **ECë³„ í†µê³„ ë¶„ì„ì´ë€?**
        ê° ë™ì§ˆì§‘í•©(EC)ë³„ë¡œ ì„ íƒí•œ ì†ì„±ë“¤ì˜ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        - ìˆ˜ì¹˜í˜•: í‰ê· , í‘œì¤€í¸ì°¨, ìµœì†Œ/ìµœëŒ€ê°’
        - ë²”ì£¼í˜•: ê³ ìœ ê°’ ìˆ˜, ì—”íŠ¸ë¡œí”¼, ìµœë¹ˆê°’
        """)
        
        # í†µê³„ ëŒ€ìƒ ì»¬ëŸ¼ ì„ íƒ
        all_cols = df.columns.tolist()
        available_cols = [col for col in all_cols if col not in selected_qi]
        
        target_cols = st.multiselect(
            "í†µê³„ë¥¼ ê³„ì‚°í•  ì†ì„± ì„ íƒ",
            available_cols,
            help="ì¤€ì‹ë³„ìë¥¼ ì œì™¸í•œ ì†ì„±ë“¤ì„ ì„ íƒí•˜ì„¸ìš”",
            key="ec_stat_target_cols"
        )
        
        if target_cols:
            # EC í•„í„° ì˜µì…˜
            use_filter = st.checkbox("íŠ¹ì • ECë§Œ ì¡°íšŒ", key="ec_filter_check")
            
            ec_selection = None
            if use_filter:
                st.markdown("**ì¡°íšŒí•  EC ì¡°ê±´ ì…ë ¥**")
                ec_filters = []
                
                # ê° ì¤€ì‹ë³„ìë³„ í•„í„° ì…ë ¥
                filter_cols = st.columns(len(selected_qi))
                for i, qi in enumerate(selected_qi):
                    with filter_cols[i]:
                        # í•´ë‹¹ ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ ê°€ì ¸ì˜¤ê¸°
                        unique_vals = df[qi].dropna().unique()
                        
                        if len(unique_vals) <= 20:
                            # ê°’ì´ ì ìœ¼ë©´ ì„ íƒë°•ìŠ¤
                            selected_val = st.selectbox(
                                f"{qi}",
                                ["ì „ì²´"] + list(unique_vals),
                                key=f"ec_filter_{qi}"
                            )
                            if selected_val != "ì „ì²´":
                                ec_filters.append({qi: selected_val})
                        else:
                            # ê°’ì´ ë§ìœ¼ë©´ í…ìŠ¤íŠ¸ ì…ë ¥
                            input_val = st.text_input(
                                f"{qi}",
                                placeholder="ê°’ ì…ë ¥",
                                key=f"ec_filter_input_{qi}"
                            )
                            if input_val:
                                # ìˆ«ì ë³€í™˜ ì‹œë„
                                try:
                                    if df[qi].dtype in ['int64', 'float64']:
                                        ec_filters.append({qi: float(input_val)})
                                    else:
                                        ec_filters.append({qi: input_val})
                                except:
                                    ec_filters.append({qi: input_val})
                
                # í•„í„° ì¡°í•©
                if ec_filters:
                    ec_selection = [dict(pair for d in ec_filters for pair in d.items())]
            
            # í†µê³„ ê³„ì‚° ë²„íŠ¼
            if st.button("ğŸ“Š ECë³„ í†µê³„ ê³„ì‚°", key="calc_ec_stats"):
                with st.spinner("ECë³„ í†µê³„ ê³„ì‚° ì¤‘..."):
                    try:
                        # í†µê³„ ê³„ì‚°
                        ec_stats_df = calculate_ec_statistics(
                            df=df,
                            ec_cols=selected_qi,
                            target_cols=target_cols,
                            ec_selection=ec_selection
                        )
                        
                        if len(ec_stats_df) == 0:
                            st.warning("ì¡°ê±´ì— ë§ëŠ” ECê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            # ê²°ê³¼ í‘œì‹œ
                            st.success(f"âœ… {len(ec_stats_df)}ê°œ ECì— ëŒ€í•œ í†µê³„ ê³„ì‚° ì™„ë£Œ!")
                            
                            # ìš”ì•½ ì •ë³´
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("ì „ì²´ EC ìˆ˜", f"{len(ec_stats_df):,}ê°œ")
                            with col2:
                                avg_size = ec_stats_df['EC_SIZE'].mean()
                                st.metric("í‰ê·  EC í¬ê¸°", f"{avg_size:.1f}")
                            with col3:
                                total_records = ec_stats_df['EC_SIZE'].sum()
                                st.metric("ì´ ë ˆì½”ë“œ ìˆ˜", f"{total_records:,}")
                            
                            # í†µê³„ í…Œì´ë¸” í‘œì‹œ
                            st.markdown("### ğŸ“Š ECë³„ í†µê³„ ê²°ê³¼")
                            
                            # í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ
                            display_cols = selected_qi + ['EC_SIZE']
                            for target_col in target_cols:
                                # í•´ë‹¹ target_col ê´€ë ¨ í†µê³„ ì»¬ëŸ¼ë“¤ ì¶”ê°€
                                stat_cols = [col for col in ec_stats_df.columns if col.startswith(f'{target_col}_')]
                                display_cols.extend(stat_cols)
                            
                            # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
                            st.dataframe(
                                ec_stats_df[display_cols],
                                use_container_width=True,
                                height=400
                            )
                            
                            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                            csv = ec_stats_df.to_csv(index=False, encoding='utf-8-sig')
                            st.download_button(
                                label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                                data=csv.encode('utf-8-sig'),
                                file_name=f"ec_statistics_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                mime="text/csv"
                            )
                            
                            # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                            if 'ec_statistics' not in st.session_state:
                                st.session_state.ec_statistics = {}
                            st.session_state.ec_statistics['latest'] = {
                                'df': ec_stats_df,
                                'ec_cols': selected_qi,
                                'target_cols': target_cols,
                                'timestamp': pd.Timestamp.now()
                            }
                            
                                                        # ECë³„ ì—”íŠ¸ë¡œí”¼ ë¶„í¬ ì‹œê°í™”
                            if any(col.endswith('_entropy') for col in ec_stats_df.columns):
                                with st.expander("ğŸ“ˆ ì—”íŠ¸ë¡œí”¼ ë¶„í¬ ì‹œê°í™”", expanded=False):
                                    entropy_cols = [col for col in ec_stats_df.columns if col.endswith('_entropy')]
                                    
                                    for ent_col in entropy_cols:
                                        fig, ax = plt.subplots(figsize=(8, 4))
                                        
                                        # íˆìŠ¤í† ê·¸ë¨
                                        ec_stats_df[ent_col].hist(bins=20, ax=ax, edgecolor='black', alpha=0.7)
                                        ax.set_xlabel('ì—”íŠ¸ë¡œí”¼')
                                        ax.set_ylabel('EC ìˆ˜')
                                        ax.set_title(f'{ent_col.replace("_entropy", "")} ì—”íŠ¸ë¡œí”¼ ë¶„í¬')
                                        
                                        # í‰ê· ì„  ì¶”ê°€
                                        mean_entropy = ec_stats_df[ent_col].mean()
                                        ax.axvline(mean_entropy, color='red', linestyle='--', 
                                                label=f'í‰ê· : {mean_entropy:.3f}')
                                        ax.legend()
                                        
                                        st.pyplot(fig)
                                        plt.close()
                    
                    except Exception as e:
                        st.error(f"í†µê³„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        st.exception(e)


    # k-ìµëª…ì„± ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
    if st.button("ğŸ” k-ìµëª…ì„± ë¶„ì„ ì‹¤í–‰", type="primary", disabled=len(selected_qi) == 0):
        if len(selected_qi) == 0:
            st.error("ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ ì¤€ì‹ë³„ìë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
        
        with st.spinner("k-ìµëª…ì„± ë¶„ì„ ì¤‘..."):
            # ìƒ˜í”Œë§ ì ìš©
            if use_sampling and sample_size < len(df): 
                analysis_df = df.sample(n=sample_size)
            else:
                analysis_df = df
            
            # k-ìµëª…ì„± ê³„ì‚°
            try:
                k_value, k_stats = calculate_k_anonymity(
                    analysis_df,
                    selected_qi,
                    k_threshold,
                    sample_rate  # ğŸ”´ ì¶”ê°€
                )
                
                # ê²°ê³¼ í‘œì‹œ
                st.markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼")
                

                # ì£¼ìš” ì§€í‘œ í‘œì‹œ (ğŸ”´ EMP ì¶”ê°€ë¡œ 5ê°œ ì»¬ëŸ¼ìœ¼ë¡œ ë³€ê²½)
                col_a, col_b, col_c, col_d, col_e = st.columns(5)

                with col_a:
                    st.metric(
                        "ìµœì†Œ kê°’",
                        f"{k_stats['min_k']}",
                        delta=f"{k_stats['min_k'] - k_threshold}" if k_stats['min_k'] < k_threshold else None,
                        delta_color="inverse"
                    )

                with col_b:
                    st.metric(
                        "í‰ê·  kê°’",
                        f"{k_stats['avg_k']:.1f}"
                    )

                with col_c:
                    st.metric(
                        "ì¤‘ì•™ê°’",
                        f"{k_stats['median_k']}"
                    )

                with col_d:
                    risk_ratio = k_stats['risk_records'] / len(analysis_df) * 100
                    st.metric(
                        "ìœ„í—˜ ë ˆì½”ë“œ",
                        f"{k_stats['risk_records']:,}ê°œ",
                        delta=f"{risk_ratio:.1f}%",
                        delta_color="inverse"
                    )

                # ğŸ”´ EMP ë©”íŠ¸ë¦­ ì¶”ê°€
                with col_e:
                    emp_value = k_stats['emp']
                    emp_percent = emp_value * 100
                    st.metric(
                        "EMP",
                        f"{emp_percent:.2f}%",
                        delta=k_stats['emp_risk_level'],
                        delta_color="inverse" if emp_value > 0.05 else "normal"
                    )

                # ğŸ”´ EMP ìƒì„¸ ì •ë³´ ì¶”ê°€
                st.markdown("### ğŸ¯ EMP (Expected Match Probability) ë¶„ì„")
                emp_col1, emp_col2, emp_col3 = st.columns(3)

                with emp_col1:
                    st.info(f"""
                    **EMP ê°’**: {k_stats['emp']:.6f} ({k_stats['emp']*100:.3f}%)
                    **ìœ„í—˜ ìˆ˜ì¤€**: {k_stats['emp_risk_level']}
                    """)

                with emp_col2:
                    st.info(f"""
                    **í‘œë³¸ë¥ **: {k_stats['sample_rate']}
                    **í‰ê·  ê°œì¸ ìœ„í—˜ë„**: {k_stats['avg_individual_risk']:.4f}
                    """)

                with emp_col3:
                    st.info(f"""
                    **ê³ ìœ„í—˜ ë ˆì½”ë“œ**: {k_stats['high_risk_records']:,}ê°œ
                    **ì „ì²´ ìœ„í—˜ë„ í•©**: {k_stats['total_risk_sum']:.2f}
                    """)

                # EMP í•´ì„ ê°€ì´ë“œ
                with st.expander("ğŸ’¡ EMP í•´ì„ ê°€ì´ë“œ", expanded=False):
                    st.markdown("""
                    **EMP(Expected Match Probability)**ëŠ” ë°ì´í„°ì…‹ì—ì„œ ê°œì¸ì´ ì¬ì‹ë³„ë  ê¸°ëŒ€ í™•ë¥ ì…ë‹ˆë‹¤.
                    
                    - **< 1%**: ë§¤ìš° ì•ˆì „ (ì¬ì‹ë³„ ìœ„í—˜ ë§¤ìš° ë‚®ìŒ)
                    - **1-5%**: ì•ˆì „ (ì¬ì‹ë³„ ìœ„í—˜ ë‚®ìŒ)
                    - **5-10%**: ì£¼ì˜ í•„ìš” (ì¤‘ê°„ ìˆ˜ì¤€ ìœ„í—˜)
                    - **10-20%**: ìœ„í—˜ (ì¬ì‹ë³„ ìœ„í—˜ ë†’ìŒ)
                    - **> 20%**: ë§¤ìš° ìœ„í—˜ (ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”)
                    
                    **ê³„ì‚° ë°©ë²•**: Skinner-Elliot ëª¨ë¸ ê¸°ë°˜
                    - ê°œë³„ ìœ„í—˜ë„ = 1 / (í‘œë³¸ë¥  Ã— ECí¬ê¸°)
                    - EMP = (í‘œë³¸ë¥  / ì „ì²´ë ˆì½”ë“œìˆ˜) Ã— Î£ê°œë³„ìœ„í—˜ë„
                    """)
                
                # kê°’ ë¶„í¬ ì‹œê°í™”
                st.markdown("### ğŸ“ˆ kê°’ ë¶„í¬")
                create_k_distribution_chart(k_stats['k_distribution'], k_threshold)
                
                # ìœ„í—˜ ë ˆì½”ë“œ ìƒì„¸
                if k_stats['risk_records'] > 0:
                    with st.expander(f"âš ï¸ ìœ„í—˜ ë ˆì½”ë“œ ìƒì„¸ (k < {k_threshold})", expanded=False):
                        risk_df = k_stats['risk_records_detail']
                        st.dataframe(
                            risk_df.head(100),  # ìµœëŒ€ 100ê°œë§Œ í‘œì‹œ
                            use_container_width=True
                        )
                        
                        if len(risk_df) > 100:
                            st.info(f"ì „ì²´ {len(risk_df)}ê°œ ì¤‘ ìƒìœ„ 100ê°œë§Œ í‘œì‹œë©ë‹ˆë‹¤.")
                
                # ë¶„ì„ ì •ë³´ ì €ì¥ (ë‹¤ë¥¸ íƒ­ì—ì„œ ì‚¬ìš©)
                                
                if 'privacy_analysis' not in st.session_state:
                    st.session_state.privacy_analysis = {}

                st.session_state.privacy_analysis['k_anonymity'] = {
                    'quasi_identifiers': selected_qi,
                    'k_value': k_value,
                    'k_stats': k_stats,
                    'threshold': k_threshold,
                    'sampled': use_sampling,
                    'sample_rate': sample_rate,  # ğŸ”´ ì¶”ê°€
                    'emp': k_stats['emp'],  # ğŸ”´ ì¶”ê°€
                    'emp_risk_level': k_stats['emp_risk_level']  # ğŸ”´ ì¶”ê°€
}
                
                st.session_state.privacy_analysis['k_anonymity'] = {
                    'quasi_identifiers': selected_qi,
                    'k_value': k_value,
                    'k_stats': k_stats,
                    'threshold': k_threshold,
                    'sampled': use_sampling
                }
                
                st.success("âœ… k-ìµëª…ì„± ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                
            except Exception as e:
                st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    elif len(selected_qi) == 0:
        st.info("ğŸ‘† ì¤€ì‹ë³„ìë¥¼ ì„ íƒí•˜ê³  ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

def calculate_k_anonymity(
        df: pd.DataFrame,
        quasi_identifiers: List[str],
        k_threshold: int = 5,
        sample_rate: float = 1.0  # ğŸ”´ ìƒˆ íŒŒë¼ë¯¸í„° ì¶”ê°€
) -> Tuple[int, Dict]:
    """
    ì„ íƒí•œ ì¤€ì‹ë³„ìì— ëŒ€í•´ k-ìµëª…ì„± í†µê³„ ë° EMP ê³„ì‚°
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        quasi_identifiers: ì¤€ì‹ë³„ì ë¦¬ìŠ¤íŠ¸
        k_threshold: kê°’ ì„ê³„ê°’
        sample_rate: í‘œë³¸ë¥  (fê°’, 0 < f <= 1)
    
    Returns:
        k_value : ì „ì²´ ë°ì´í„°ì˜ ìµœì†Œ k
        k_stats : ìƒì„¸ í†µê³„ ë”•ì…”ë„ˆë¦¬ (EMP í¬í•¨)
    """
    # 1) ë™ì§ˆì§‘í•© í¬ê¸° ê³„ì‚°
    group_sizes = (
        df.groupby(quasi_identifiers)
          .size()
          .reset_index(name='count')
    )

    k_value = int(group_sizes['count'].min())

    # 2) ìœ„í—˜ ë ˆì½”ë“œ( k < k_threshold ) ì§‘í•© ì¶”ì¶œ
    risk_ec = group_sizes[group_sizes['count'] < k_threshold][quasi_identifiers]
    risk_records_detail = df.merge(
        risk_ec,
        on=quasi_identifiers,
        how='inner'
    )
    
    # ğŸ”´ 3) EMP ê³„ì‚° ì¶”ê°€
    # EMP ê³„ì‚°ì„ ìœ„í•œ ê°œë³„ ìœ„í—˜ë„ ê³„ì‚°
    n = len(df)  # ì „ì²´ ë ˆì½”ë“œ ìˆ˜
    total_risk = 0.0
    
    # ê° ë ˆì½”ë“œì˜ EC í¬ê¸°ë¥¼ ì°¾ì•„ì„œ ìœ„í—˜ë„ ê³„ì‚°
    for _, row in df.iterrows():
        # í•´ë‹¹ ë ˆì½”ë“œê°€ ì†í•œ EC ì°¾ê¸°
        ec_condition = True
        for qi in quasi_identifiers:
            ec_condition &= (group_sizes[qi] == row[qi])
        
        # EC í¬ê¸° ì°¾ê¸° (ë” íš¨ìœ¨ì ì¸ ë°©ë²•)
        ec_match = group_sizes
        for qi in quasi_identifiers:
            ec_match = ec_match[ec_match[qi] == row[qi]]
        
        if len(ec_match) > 0:
            ec_size = ec_match.iloc[0]['count']
            # Skinner-Elliot ê³µì‹: risk_i = 1 / (f * |EC_i|)
            risk_i = 1 / (sample_rate * ec_size)
            if risk_i > 1:
                risk_i = 1  # ìœ„í—˜ë„ëŠ” ìµœëŒ€ 1
            total_risk += risk_i
    
    # ë” íš¨ìœ¨ì ì¸ ë°©ë²•: mergeë¥¼ ì‚¬ìš©
    # ê° ë ˆì½”ë“œì— EC í¬ê¸° ì •ë³´ ì¶”ê°€
    df_with_ec_size = df.merge(
        group_sizes.rename(columns={'count': 'ec_size'}),
        on=quasi_identifiers,
        how='left'
    )
    
    # ê° ë ˆì½”ë“œì˜ ìœ„í—˜ë„ ê³„ì‚°
    df_with_ec_size['risk_i'] = 1 / (sample_rate * df_with_ec_size['ec_size'])
    df_with_ec_size['risk_i'] = df_with_ec_size['risk_i'].clip(upper=1)  # ìµœëŒ€ê°’ 1ë¡œ ì œí•œ
    
    total_risk = df_with_ec_size['risk_i'].sum()
    
    # EMP = (f / N) * Î£ risk_i
    emp = (sample_rate / n) * total_risk

    # 4) í†µê³„ ë”•ì…”ë„ˆë¦¬ ì‘ì„±
    k_stats = {
        'min_k': k_value,
        'max_k': int(group_sizes['count'].max()),
        'avg_k': float(group_sizes['count'].mean()),
        'median_k': int(group_sizes['count'].median()),
        'k_distribution': group_sizes['count']
                          .value_counts()
                          .sort_index()
                          .to_dict(),
        'risk_records': len(risk_records_detail),
        'risk_records_detail': risk_records_detail,
        # ğŸ”´ EMP ê´€ë ¨ í†µê³„ ì¶”ê°€
        'emp': emp,
        'sample_rate': sample_rate,
        'total_risk_sum': total_risk,
        'avg_individual_risk': total_risk / n,
        'high_risk_records': len(df_with_ec_size[df_with_ec_size['risk_i'] >= 0.5]),  # ìœ„í—˜ë„ 50% ì´ìƒ
        'emp_risk_level': get_emp_risk_level(emp)  # ìœ„í—˜ ìˆ˜ì¤€ í‰ê°€
    }

    return k_value, k_stats

# ğŸ”´ EMP ìœ„í—˜ ìˆ˜ì¤€ í‰ê°€ í•¨ìˆ˜ ì¶”ê°€
def get_emp_risk_level(emp: float) -> str:
    """EMP ê°’ì— ë”°ë¥¸ ìœ„í—˜ ìˆ˜ì¤€ í‰ê°€"""
    if emp < 0.01:
        return "ë§¤ìš° ë‚®ìŒ"
    elif emp < 0.05:
        return "ë‚®ìŒ"
    elif emp < 0.1:
        return "ì¤‘ê°„"
    elif emp < 0.2:
        return "ë†’ìŒ"
    else:
        return "ë§¤ìš° ë†’ìŒ"

def create_k_distribution_chart(k_distribution: Dict[int, int], threshold: int):
    """kê°’ ë¶„í¬ ì°¨íŠ¸ ìƒì„± (Streamlit ë‚´ì¥ ì°¨íŠ¸ ì‚¬ìš©)"""
    # ë°ì´í„° ì¤€ë¹„
    k_values = list(k_distribution.keys())
    counts = list(k_distribution.values())
    
    # DataFrameìœ¼ë¡œ ë³€í™˜
    chart_data = pd.DataFrame({
        'kê°’': k_values,
        'ê·¸ë£¹ ìˆ˜': counts,
        'ìƒíƒœ': ['ìœ„í—˜' if k < threshold else 'ì•ˆì „' for k in k_values]
    })
    
    # Streamlit ì°¨íŠ¸
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # ë§‰ëŒ€ ì°¨íŠ¸
        st.bar_chart(
            data=chart_data.set_index('kê°’')['ê·¸ë£¹ ìˆ˜'],
            height=400
        )
    
    with col2:
        # í†µê³„ ì •ë³´
        st.metric("ì„ê³„ê°’", f"k = {threshold}")
        st.metric("ìœ„í—˜ ê·¸ë£¹", f"{len([k for k in k_values if k < threshold])}ê°œ")
        st.metric("ì•ˆì „ ê·¸ë£¹", f"{len([k for k in k_values if k >= threshold])}ê°œ")
    
    # ì¶”ê°€ ì •ë³´
    if any(k < threshold for k in k_values):
        st.warning(f"âš ï¸ k < {threshold}ì¸ ê·¸ë£¹ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
    else:
        st.success(f"âœ… ëª¨ë“  ê·¸ë£¹ì´ k â‰¥ {threshold}ë¥¼ ë§Œì¡±í•©ë‹ˆë‹¤.")

def render_utility_evaluation_section(_: pd.DataFrame):
    """ìœ ìš©ì„± í‰ê°€ íƒ­ â€“ ê°œì„ ëœ ë²„ì „"""
    st.subheader("ğŸ“ˆ ìœ ìš©ì„± í‰ê°€")
    
    # ì§€í‘œ ë©”íƒ€ ì •ë³´ (ê°œì„ ëœ ì„ê³„ê°’)
    METRIC_INFO = {
        'U1': {
            'name': 'í‰ê· ê°’ ì°¨ì´',
            'desc': 'ë‘ ë°ì´í„°ì…‹ í‰ê· ê°’ì´ ì–¼ë§ˆë‚˜ ë‹¤ë¥¸ì§€ ì¸¡ì • (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)',
            'thresholds': {'excellent': 0.05, 'good': 0.1, 'fair': 0.5},
            'lower_better': True
        },
        'U2': {
            'name': 'ìƒê´€ê³„ìˆ˜ ë³´ì¡´',
            'desc': 'ì›ë³¸Â·ë¹„ì‹ë³„ ìƒê´€ê³„ìˆ˜ ì°¨ì´ í‰ê·  (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)',
            'thresholds': {'excellent': 0.01, 'good': 0.05, 'fair': 0.1},
            'lower_better': True
        },
        'U3': {
            'name': 'ì½”ì‚¬ì¸ ìœ ì‚¬ë„',
            'desc': 'ë²¡í„° ìœ ì‚¬ë„ í‰ê·  (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)',
            'thresholds': {'excellent': 0.99, 'good': 0.95, 'fair': 0.9},
            'lower_better': False
        },
        'U4': {
            'name': 'ì •ê·œí™” ê±°ë¦¬',
            'desc': 'ì •ê·œí™” SSE í•© (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)',
            'thresholds': {'excellent': 0.01, 'good': 0.05, 'fair': 0.1},
            'lower_better': True
        },
        'U5': {
            'name': 'í‘œì¤€í™” ê±°ë¦¬',
            'desc': 'í‘œì¤€í™” SSE í•© (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)',
            'thresholds': {'excellent': 0.1, 'good': 0.5, 'fair': 1.0},
            'lower_better': True
        },
        'U6': {
            'name': 'ë™ì§ˆì§‘í•© ë¶„ì‚°',
            'desc': 'ë™ì§ˆì§‘í•© ë‚´ ë¯¼ê°ê°’ ë¶„ì‚° í‰ê·  (ë‚®ì„ìˆ˜ë¡ ì •ë³´ ìœ ì§€)',
            'thresholds': {'excellent': 0.5, 'good': 1.0, 'fair': 2.0},
            'lower_better': True
        },
        'U7': {
            'name': 'ì •ê·œí™” ì§‘í•©í¬ê¸°',
            'desc': '(N/N_EC)/k : ë™ì§ˆì§‘í•© í¬ê¸° ì§€í‘œ (ë‚®ì„ìˆ˜ë¡ ì•ˆì „)',
            'thresholds': {'excellent': 1.0, 'good': 2.0, 'fair': 5.0},
            'lower_better': True
        },
        'U8': {
            'name': 'ë¹„ê· ì¼ ì—”íŠ¸ë¡œí”¼',
            'desc': 'ë³€ê²½ ë ˆì½”ë“œ ì—”íŠ¸ë¡œí”¼ (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì›ë³¸ê³¼ ìœ ì‚¬)',
            'thresholds': {'excellent': 0.1, 'good': 0.3, 'fair': 0.5},
            'lower_better': True
        },
        'U9': {
            'name': 'ìµëª…í™”ìœ¨',
            'desc': 'ë¹„ì‹ë³„ ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ë‚¨ì•˜ëŠ”ì§€ (%) (ë†’ì„ìˆ˜ë¡ í™œìš© â†‘)',
            'thresholds': {'excellent': 95, 'good': 90, 'fair': 80},
            'lower_better': False
        },
    }
    
    # ë„ì›€ë§ í† ê¸€
    show_help = st.toggle("ğŸ‘¶ ì²˜ìŒì´ë¼ë©´ ë„ì›€ë§ ë³´ê¸°", value=False)
    if show_help:
        st.info("**ìœ ìš©ì„±(U) ì§€í‘œë€?**\n\n" + 
                "\n".join([f"â€¢ **{k} ({v['name']})** : {v['desc']}" 
                          for k, v in METRIC_INFO.items()]))

    # 1. ë°ì´í„° ì¡´ì¬ í™•ì¸
    if 'df' not in st.session_state or 'df_processed' not in st.session_state:
        st.warning("ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê³  ë¹„ì‹ë³„í™”ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        return

    orig_df = st.session_state.df
    proc_df = st.session_state.df_processed

    # 2. ë¬´ì¡°ê±´ ë³€í™˜ëœ ë°ì´í„° íƒ€ì… ì‚¬ìš©
    st.info("ğŸ“Œ ë³€í™˜ëœ ë°ì´í„°ì˜ íƒ€ì…ì„ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.")
    
    # ë³€í™˜ëœ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ì»¬ëŸ¼ ë¶„ë¥˜
    numeric_cols = proc_df.select_dtypes(include='number').columns.tolist()
    all_cols = proc_df.columns.tolist()

    # 3. í‰ê°€ ëŒ€ìƒ ì»¬ëŸ¼
    if 'util_cols' not in st.session_state:
        st.session_state.util_cols = numeric_cols

    st.markdown("### â‘  í‰ê°€ ëŒ€ìƒ ì»¬ëŸ¼")
    left, right = st.columns([3, 1])
    with right:
        if st.button("ìˆ«ìí˜•ë§Œ"):
            st.session_state.util_cols = numeric_cols
            st.rerun()

        if st.button("ì „ì²´"):
            st.session_state.util_cols = all_cols
            st.rerun()

        if st.button("ì´ˆê¸°í™”"):
            st.session_state.util_cols = []
            st.rerun()

    with left:
        sel_cols = st.multiselect(
            "ì»¬ëŸ¼ ì„ íƒ", all_cols,
            default=st.session_state.util_cols, key="util_cols"
        )
    
    if not sel_cols:
        st.info("ì»¬ëŸ¼ì„ í•œ ê°œ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.")
        return
    sel_num = [c for c in sel_cols if c in numeric_cols]

    # UtilityMetrics ì¤€ë¹„
    from modules.privacy_metrics.utility_metrics import UtilityMetrics
    utility_analyzer = UtilityMetrics(orig_df, proc_df) 

    # 4. ì§€í‘œ ì„ íƒ & QI ì˜µì…˜
    st.markdown("### â‘¡ ì§€í‘œ ì„ íƒ")
    
    metrics = st.multiselect(
        "ì‹¤í–‰í•  ì§€í‘œ", list(METRIC_INFO.keys()),
        default=['U1', 'U2', 'U9'],
        format_func=lambda m: f"{m} â€“ {METRIC_INFO[m]['name']}"
    )

    # ì„ íƒí•œ ì§€í‘œ ì„¤ëª… íŒ¨ë„
    if metrics:
        with st.container():
            st.markdown("#### ì„ íƒ ì§€í‘œ ì„¤ëª…")
            for m in metrics:
                st.markdown(f"**{m} â€“ {METRIC_INFO[m]['name']}**  \n"
                            f"{METRIC_INFO[m]['desc']}")
    
    qi_cols, sens_attr = [], None
    if any(m in metrics for m in ('U6', 'U7')):
        with st.expander("ğŸ” QIÂ·ë¯¼ê°ì†ì„±", expanded=True):
            qi_cols = st.multiselect("ì¤€ì‹ë³„ì(QI)", options=sel_cols)
            if qi_cols:
                cand = [c for c in sel_num if c not in qi_cols]
                if cand:
                    sens_attr = st.selectbox("ë¯¼ê°ì†ì„±", cand)

    # 5. ìƒ˜í”Œë§
    st.markdown("### â‘¢ ìƒ˜í”Œë§")
    use_samp = st.toggle("ìƒ˜í”Œë§ ì‚¬ìš©", value=True)
    samp_rows = st.slider(
        "ìƒ˜í”Œ í–‰ ìˆ˜", 10_000, min(1_000_000, len(orig_df)),
        100_000, step=10_000, disabled=not use_samp, format="%d í–‰"
    )
    analysis_df = orig_df.sample(samp_rows, random_state=42) if use_samp and samp_rows < len(orig_df) else orig_df

    # 6. ì‹¤í–‰
    st.markdown("### â‘£ í‰ê°€ ì‹¤í–‰")
    if st.button("ğŸš€ ì„ íƒí•œ ì§€í‘œ ì‹¤í–‰", type="primary"):
        run_id = uuid.uuid4().hex[:8]
        summary, detail_results = [], {}
        prog = st.progress(0.0)
        total = len(metrics)

        # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— í–‰ ì¶”ê°€í•˜ëŠ” í—¬í¼ (ê°œì„ )
        def push(metric: str, res: dict, used_cols: list):
            """summaryÂ·detail ë‘ ê³³ì— ê²°ê³¼ë¥¼ ì €ì¥"""
            metric_info = METRIC_INFO[metric]
            
            # U2 ìƒê´€ê³„ìˆ˜ëŠ” íŠ¹ë³„ ì²˜ë¦¬
            if metric == 'U2' and res.get('status') == 'success':
                # ì „ì²´ ì ìˆ˜
                score = res.get('total_score', 0)
                summary.append({
                    'ì§€í‘œ': metric,
                    'ì§€í‘œëª…': metric_info['name'],
                    'ì»¬ëŸ¼': "ì „ì²´ ìƒê´€ê³„ìˆ˜",
                    'ì ìˆ˜': round(score, 4) if isinstance(score, (int, float)) else score,
                    'í‰ê°€': get_score_badge(metric, score, METRIC_INFO)
                })
                
                # ê°œë³„ ìŒ ê²°ê³¼
                if 'pair_results' in res:
                    for pair, pair_res in res['pair_results'].items():
                        summary.append({
                            'ì§€í‘œ': metric,
                            'ì§€í‘œëª…': metric_info['name'],
                            'ì»¬ëŸ¼': pair,
                            'ì ìˆ˜': round(pair_res['difference'], 4),
                            'í‰ê°€': get_score_badge(metric, pair_res['difference'], METRIC_INFO)
                        })
            
            # ì»¬ëŸ¼ë³„ ì ìˆ˜ë¥¼ ë¶„í•´í•´ì„œ ë³´ì—¬ì¤˜ì•¼ í•˜ëŠ” ì§€í‘œ
            elif metric in ('U1', 'U3', 'U4', 'U5') and res.get('status') == 'success':
                for col, det in res['column_results'].items():
                    if 'error' in det:
                        continue
                    val = det.get('difference') or det.get('cosine_similarity') \
                          or det.get('normalized_sse') or det.get('sse')
                    summary.append({
                        'ì§€í‘œ': metric,
                        'ì§€í‘œëª…': metric_info['name'],
                        'ì»¬ëŸ¼': col,
                        'ì ìˆ˜': round(val, 4) if isinstance(val, (int, float)) else val,
                        'í‰ê°€': get_score_badge(metric, val, METRIC_INFO)
                    })
            else:
                score = res.get('total_score') or res.get('average_score')
                summary.append({
                    'ì§€í‘œ': metric,
                    'ì§€í‘œëª…': metric_info['name'],
                    'ì»¬ëŸ¼': ", ".join(used_cols) if used_cols else '-',
                    'ì ìˆ˜': round(score, 4) if isinstance(score, (int, float)) else score,
                    'í‰ê°€': get_score_badge(metric, score, METRIC_INFO)
                })
            detail_results[metric] = res

        # ì„ íƒí•œ ì§€í‘œ ìˆœì°¨ ì‹¤í–‰
        for i, m in enumerate(metrics, 1):
            prog.progress(i / total, text=f"{m} ê³„ì‚° ì¤‘â€¦")

            if m == 'U1':
                push(m, utility_analyzer.calculate_u1_ma(sel_num), sel_num)
            elif m == 'U2':
                push(m, utility_analyzer.calculate_u2_mc(sel_num), sel_num)
            elif m == 'U3':
                push(m, utility_analyzer.calculate_u3_cs(sel_num), sel_num)
            elif m == 'U4':
                push(m, utility_analyzer.calculate_u4_ned(sel_num), sel_num)
            elif m == 'U5':
                push(m, utility_analyzer.calculate_u5_sed(sel_num), sel_num)
            elif m == 'U6' and qi_cols and sens_attr:
                push(m, utility_analyzer.calculate_u6_md_ecm(qi_cols, sens_attr), [sens_attr])
            elif m == 'U7' and qi_cols:
                push(m, utility_analyzer.calculate_u7_na_ecsm(qi_cols), qi_cols)
            elif m == 'U8':
                push(m, utility_analyzer.calculate_u8_nuem(sel_num), sel_num)
            elif m == 'U9':
                push(m, utility_analyzer.calculate_u9_ar(), [])

        prog.empty()

        # íˆìŠ¤í† ë¦¬ ì„¸ì…˜ ìŠ¤í† ë¦¬ì§€
        st.session_state.setdefault('util_history', []).append({
            'id':     run_id,
            'time':   time.strftime("%H:%M:%S"),
            'rows':   len(analysis_df),
            'summary': summary,
            'detail':  detail_results,
        })

    # 7. ê²°ê³¼ í‘œì‹œ (ê°œì„ )
    if st.session_state.get("util_history"):
        latest = st.session_state.util_history[-1]
        st.markdown(f"### â‘¤ ê²°ê³¼ ìš”ì•½ ({latest['time']})")

        # A. ì£¼ìš” ë©”íŠ¸ë¦­ ì¹´ë“œ
        card_metrics = ["U1", "U2", "U3", "U9"]
        cols = st.columns(len(card_metrics))

        for col, m in zip(cols, card_metrics):
            # í•´ë‹¹ ì§€í‘œì˜ ì²« ë²ˆì§¸ ê²°ê³¼ ì°¾ê¸°
            row = next((r for r in latest["summary"] if r["ì§€í‘œ"] == m), None)
            if not row:
                col.empty()
                continue

            # ìƒ‰ìƒê³¼ ì•„ì´ì½˜ ê²°ì •
            badge = row['í‰ê°€']
            emoji = badge.split()[0] if badge else "âšª"
            
            col.metric(
                label=f"{m} - {METRIC_INFO[m]['name']}",
                value=f"{row['ì ìˆ˜']} {emoji}",
                help=badge
            )

        # B. ê°œì„ ëœ ìš”ì•½í‘œ
        df_sum = pd.DataFrame(latest["summary"])
        
        # ì»¬ëŸ¼ ìˆœì„œ ì¡°ì •
        display_cols = ['ì§€í‘œ', 'ì§€í‘œëª…', 'ì»¬ëŸ¼', 'ì ìˆ˜', 'í‰ê°€']
        df_sum = df_sum[display_cols]
        
        # ìŠ¤íƒ€ì¼ ì ìš©
        styled_df = df_sum.style.apply(lambda x: [
            'background-color: #e8f5e9' if 'ğŸŸ¢' in str(v) else
            'background-color: #fff3e0' if 'ğŸŸ¡' in str(v) else
            'background-color: #ffebee' if 'ğŸ”´' in str(v) else ''
            for v in x
        ], axis=1)
        
        st.dataframe(styled_df, hide_index=True, use_container_width=True)

        # C. ìƒì„¸ ê²°ê³¼
        with st.expander("ğŸ” ìƒì„¸ ê²°ê³¼ ë³´ê¸°"):
            for metric in latest["detail"]:
                st.markdown(f"#### {metric} - {METRIC_INFO[metric]['name']}")
                st.json(latest["detail"][metric])

        # D. ë‹¤ìš´ë¡œë“œ
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                "â¬‡ï¸ ìš”ì•½ CSV",
                df_sum.to_csv(index=False, encoding="utf-8-sig").encode(),
                "utility_summary.csv",
            )
        with col2:
            st.download_button(
                "â¬‡ï¸ ìƒì„¸ JSON",
                json.dumps(latest["detail"], ensure_ascii=False, indent=2).encode("utf-8"),
                "utility_detail.json",
                mime="application/json",
            )

        # E. ì‹¤í–‰ íˆìŠ¤í† ë¦¬
        with st.expander("ğŸ•‘ ì‹¤í–‰ íˆìŠ¤í† ë¦¬"):
            for h in reversed(st.session_state.util_history):
                if st.button(f"{h['time']} ({h['rows']} rows)", key=h["id"]):
                    # ì„ íƒí•œ íˆìŠ¤í† ë¦¬ë¥¼ ë§¨ ë’¤ë¡œ ë³´ë‚´ê³  ë‹¤ì‹œ ë Œë”
                    st.session_state.util_history.append(
                        st.session_state.util_history.pop(
                            st.session_state.util_history.index(h)
                        )
                    )
                    st.rerun()

def calculate_ec_statistics(df: pd.DataFrame, ec_cols: List[str], target_cols: List[str], 
                          ec_selection: List[Dict] = None) -> pd.DataFrame:
    """
    ECë³„ í†µê³„ ê³„ì‚°
    
    Args:
        df: ì „ì²´ ë°ì´í„°í”„ë ˆì„
        ec_cols: EC(ë™ì§ˆì§‘í•©) ê¸°ì¤€ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        target_cols: í†µê³„ ì‚°ì¶œ ëŒ€ìƒ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        ec_selection: ì„ íƒí•œ EC ì¡°í•© (ì˜µì…˜)
    
    Returns:
        ECë³„ í†µê³„ê°€ í¬í•¨ëœ DataFrame
    """
    import scipy.stats as stats
    
    # 1. ê²°ì¸¡ê°’ ì²˜ë¦¬ ì˜µì…˜
    df_clean = df.copy()
    
    # 2. ECë³„ ê·¸ë£¹í™”
    ec_groups = df_clean.groupby(ec_cols)
    
    # 3. ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸
    results = []
    
    # 4. ê° ECì— ëŒ€í•´ í†µê³„ ê³„ì‚°
    for ec_values, group in ec_groups:
        row_data = {}
        
        # EC ì‹ë³„ì ì¶”ê°€
        if isinstance(ec_values, tuple):
            for i, col in enumerate(ec_cols):
                row_data[col] = ec_values[i]
        else:
            row_data[ec_cols[0]] = ec_values
        
        # EC í¬ê¸°
        row_data['EC_SIZE'] = len(group)
        
        # ê° target columnì— ëŒ€í•œ í†µê³„
        for target_col in target_cols:
            if target_col not in group.columns:
                continue
                
            col_data = group[target_col].dropna()
            
            # ë°ì´í„° íƒ€ì… í™•ì¸
            if pd.api.types.is_numeric_dtype(col_data):
                # ìˆ˜ì¹˜í˜• í†µê³„
                row_data[f'{target_col}_mean'] = col_data.mean() if len(col_data) > 0 else None
                row_data[f'{target_col}_std'] = col_data.std() if len(col_data) > 1 else None
                row_data[f'{target_col}_min'] = col_data.min() if len(col_data) > 0 else None
                row_data[f'{target_col}_max'] = col_data.max() if len(col_data) > 0 else None
                row_data[f'{target_col}_count'] = len(col_data)
            else:
                # ë²”ì£¼í˜• í†µê³„
                row_data[f'{target_col}_nunique'] = col_data.nunique()
                
                # ìµœë¹ˆê°’
                if len(col_data) > 0:
                    mode_result = col_data.mode()
                    row_data[f'{target_col}_mode'] = mode_result[0] if len(mode_result) > 0 else None
                    row_data[f'{target_col}_mode_ratio'] = (col_data == row_data[f'{target_col}_mode']).sum() / len(col_data)
                
                # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
                value_counts = col_data.value_counts()
                if len(value_counts) > 1:
                    probabilities = value_counts / len(col_data)
                    entropy = -sum(p * np.log2(p) for p in probabilities if p > 0)
                    row_data[f'{target_col}_entropy'] = entropy
                else:
                    row_data[f'{target_col}_entropy'] = 0.0
        
        results.append(row_data)
    
    # DataFrameìœ¼ë¡œ ë³€í™˜
    result_df = pd.DataFrame(results)
    
    # EC_SIZEë¡œ ì •ë ¬
    result_df = result_df.sort_values('EC_SIZE', ascending=True)
    
    # EC ì„ íƒ í•„í„°ë§ (ì˜µì…˜)
    if ec_selection:
        # ì„ íƒí•œ ECë§Œ í•„í„°ë§
        mask = pd.Series([False] * len(result_df))
        for selection in ec_selection:
            condition = pd.Series([True] * len(result_df))
            for col, val in selection.items():
                if col in result_df.columns:
                    condition &= (result_df[col] == val)
            mask |= condition
        result_df = result_df[mask]
    
    return result_df


def get_score_badge(metric: str, value: Any, metric_info: Dict) -> str:
    """ì ìˆ˜ë¥¼ í‰ê°€í•˜ì—¬ ë°°ì§€ ë°˜í™˜"""
    if value is None or (isinstance(value, float) and np.isnan(value)):
        return "âšª í‰ê°€ ë¶ˆê°€"
    
    if not isinstance(value, (int, float)):
        return "âšª ë¹„ìˆ˜ì¹˜"
    
    info = metric_info[metric]
    thresholds = info['thresholds']
    lower_better = info['lower_better']
    
    if lower_better:
        if value <= thresholds['excellent']:
            return "ğŸŸ¢ ìš°ìˆ˜"
        elif value <= thresholds['good']:
            return "ğŸŸ¡ ì–‘í˜¸"
        elif value <= thresholds['fair']:
            return "ğŸŸ  ë³´í†µ"
        else:
            return "ğŸ”´ ì£¼ì˜"
    else:
        if value >= thresholds['excellent']:
            return "ğŸŸ¢ ìš°ìˆ˜"
        elif value >= thresholds['good']:
            return "ğŸŸ¡ ì–‘í˜¸"
        elif value >= thresholds['fair']:
            return "ğŸŸ  ë³´í†µ"
        else:
            return "ğŸ”´ ì£¼ì˜"