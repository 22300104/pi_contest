# privacy_evaluation.py (ê°œì„  ë²„ì „)

import streamlit as st
import pandas as pd
import numpy as np
from typing import List, Dict, Tuple, Any
import matplotlib.pyplot as plt
import json, uuid, time

# k-ìµëª…ì„± ê³„ì‚°ì„ ìœ„í•œ ìƒˆë¡œìš´ ëª¨ë“ˆë„ í•„ìš”í•©ë‹ˆë‹¤
try:
    from modules.privacy_metrics.k_anonymity import KAnonymityAnalyzer
except ImportError:
    # ëª¨ë“ˆì´ ì•„ì§ ì—†ìœ¼ë©´ ì„ì‹œë¡œ ì²˜ë¦¬
    pass

# ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ì¶”ì í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
def get_analysis_summary():
    """ëª¨ë“  ë¶„ì„ ê²°ê³¼ ìš”ì•½"""
    summary = {
        'data_info': {
            'original_rows': len(st.session_state.df) if 'df' in st.session_state else 0,
            'processed_rows': len(st.session_state.df_processed) if 'df_processed' in st.session_state else 0,
        },
        'analyses': {}
    }
    
    # k-ìµëª…ì„± ê²°ê³¼
    if 'privacy_analysis' in st.session_state:
        if 'k_anonymity' in st.session_state.privacy_analysis:
            k_anon = st.session_state.privacy_analysis['k_anonymity']
            summary['analyses']['k_anonymity'] = {
                'quasi_identifiers': k_anon.get('quasi_identifiers', []),
                'k_value': k_anon.get('k_value'),
                'emp': k_anon.get('emp'),
                'sampled': k_anon.get('sampled', False)
            }
    
    # EC í†µê³„ ê²°ê³¼
    if 'ec_statistics' in st.session_state:
        if 'latest' in st.session_state.ec_statistics:
            ec_stat = st.session_state.ec_statistics['latest']
            summary['analyses']['ec_statistics'] = {
                'ec_cols': ec_stat.get('ec_cols', []),
                'target_cols': ec_stat.get('target_cols', []),
                'ec_count': len(ec_stat.get('df', [])),
                'sampled': ec_stat.get('sampled', False)
            }
    
    return summary

# ì‚¬ì´ë“œë°”ì— ë¶„ì„ ìƒíƒœ í‘œì‹œ (ì„ íƒì‚¬í•­)
def show_analysis_status():
    """ì‚¬ì´ë“œë°”ì— ë¶„ì„ ìƒíƒœ í‘œì‹œ"""
    with st.sidebar:
        st.markdown("### ğŸ“Š ë¶„ì„ ìƒíƒœ")
        
        summary = get_analysis_summary()
        
        # ë°ì´í„° ì •ë³´
        st.markdown("**ë°ì´í„°**")
        st.text(f"ì›ë³¸: {summary['data_info']['original_rows']:,}í–‰")
        st.text(f"ì²˜ë¦¬: {summary['data_info']['processed_rows']:,}í–‰")
        
        # ë¶„ì„ ì •ë³´
        if summary['analyses']:
            st.markdown("**ì™„ë£Œëœ ë¶„ì„**")
            
            if 'k_anonymity' in summary['analyses']:
                k_info = summary['analyses']['k_anonymity']
                st.text(f"âœ… k-ìµëª…ì„± (k={k_info['k_value']})")
                if k_info['emp']:
                    st.text(f"   EMP: {k_info['emp']:.3%}")
            
            if 'ec_statistics' in summary['analyses']:
                ec_info = summary['analyses']['ec_statistics']
                st.text(f"âœ… EC í†µê³„ ({ec_info['ec_count']}ê°œ)")
                
# privacy_evaluation.py ìƒë‹¨ì— ì¶”ê°€
def sync_quasi_identifiers():
    """íƒ­ ê°„ ì¤€ì‹ë³„ì ë™ê¸°í™”ë¥¼ ìœ„í•œ í—¬í¼ í•¨ìˆ˜"""
    if 'k_anonymity' in st.session_state.get('privacy_analysis', {}):
        return st.session_state.privacy_analysis['k_anonymity'].get('quasi_identifiers', [])
    return []

def get_analysis_dataframe():
    """ëª¨ë“  ë¶„ì„ì—ì„œ ë™ì¼í•œ ë°ì´í„°í”„ë ˆì„ ì‚¬ìš©"""
    # ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©, ì—†ìœ¼ë©´ ì›ë³¸ ì‚¬ìš©
    return st.session_state.get("df_processed", st.session_state.df)


def get_column_types():
    """ì „ì—­ ì„¤ì •ëœ ì»¬ëŸ¼ íƒ€ì… ë°˜í™˜"""
    return {
        'numeric': st.session_state.get('global_numeric_cols', []),
        'categorical': st.session_state.get('global_categorical_cols', []),
        'datetime': st.session_state.get('global_datetime_cols', [])
    }

def render_privacy_evaluation_tab():
    """í”„ë¼ì´ë²„ì‹œ í‰ê°€ íƒ­ ë Œë”ë§"""
    st.header("ğŸ“‹ í”„ë¼ì´ë²„ì‹œ í‰ê°€")
    
    if "df" not in st.session_state or st.session_state.df is None:
        st.warning("ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return
    
    # ê³µí†µ ë°ì´í„°í”„ë ˆì„ ì‚¬ìš©
    df = get_analysis_dataframe()
    
    # 3ê°œ íƒ­ìœ¼ë¡œ ë¶„ë¦¬
    tab1, tab2, tab3 = st.tabs([
        "ğŸ“Š k-ìµëª…ì„± ë¶„ì„", 
        "ğŸ“ˆ ECë³„ í†µê³„ ë¶„ì„",
        "ğŸ“‹ ìœ ìš©ì„± í‰ê°€"
    ])
    
    with tab1:
        render_k_anonymity_section(df)
    
    with tab2:
        render_ec_statistics_section(df)
    
    with tab3:
        render_utility_evaluation_section(df)

def render_ec_statistics_section(df: pd.DataFrame):
    """ECë³„ í†µê³„ ë¶„ì„ ì„¹ì…˜"""
    st.subheader("ğŸ“ˆ ECë³„ í†µê³„ ë¶„ì„")
    
    # ì¼ê´€ì„± ì˜µì…˜
    st.info("ğŸ’¡ Tip: k-ìµëª…ì„± ë¶„ì„ê³¼ ë™ì¼í•œ ì¤€ì‹ë³„ìë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì•„ë˜ ì˜µì…˜ì„ í™œìš©í•˜ì„¸ìš”")
    
    # k-ìµëª…ì„±ì—ì„œ ì‚¬ìš©í•œ ì¤€ì‹ë³„ì ê°€ì ¸ì˜¤ê¸°
    k_anon_qi = sync_quasi_identifiers()
    
    use_same_qi = False
    if k_anon_qi:
        use_same_qi = st.checkbox(
            f"k-ìµëª…ì„± ë¶„ì„ê³¼ ë™ì¼í•œ ì¤€ì‹ë³„ì ì‚¬ìš© ({', '.join(k_anon_qi)})",
            value=True,
            key="use_same_qi_ec"
        )
    
    # ì¤€ì‹ë³„ì ì„ íƒ
    st.markdown("### 1ï¸âƒ£ ì¤€ì‹ë³„ì ì„ íƒ")
    
    if use_same_qi and k_anon_qi:
        selected_qi = k_anon_qi
        st.success(f"âœ… k-ìµëª…ì„±ê³¼ ë™ì¼í•œ ì¤€ì‹ë³„ì ì‚¬ìš©: {', '.join(selected_qi)}")
    else:
        col1, col2 = st.columns([3, 1])
        
        with col1:
            all_cols = df.columns.tolist()
            selected_qi = st.multiselect(
                "EC ìƒì„±ì„ ìœ„í•œ ì¤€ì‹ë³„ì ì„ íƒ",
                all_cols,
                default=k_anon_qi if not use_same_qi else [],
                help="ë™ì§ˆì§‘í•©ì„ ë§Œë“¤ ê¸°ì¤€ ì»¬ëŸ¼ë“¤ì„ ì„ íƒí•˜ì„¸ìš”",
                key="ec_stat_qi_selection"
            )
        
        with col2:
            if selected_qi:
                # EC ìˆ˜ ë¯¸ë¦¬ ê³„ì‚°
                ec_count = df.groupby(selected_qi).ngroups
                st.metric("ì˜ˆìƒ EC ìˆ˜", f"{ec_count:,}ê°œ")
                st.metric("í‰ê·  EC í¬ê¸°", f"{len(df) / ec_count:.1f}")
    
    if not selected_qi:
        st.warning("ì¤€ì‹ë³„ìë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”")
        return
    
    # í†µê³„ ëŒ€ìƒ ì„ íƒ
    st.markdown("### 2ï¸âƒ£ í†µê³„ ëŒ€ìƒ ì„ íƒ")
    
    available_cols = [col for col in df.columns if col not in selected_qi]
    
    # ì»¬ëŸ¼ íƒ€ì…ë³„ ë¶„ë¥˜
    numeric_cols = df[available_cols].select_dtypes(include='number').columns.tolist()
    categorical_cols = df[available_cols].select_dtypes(include=['object', 'category']).columns.tolist()
    
    col1, col2 = st.columns(2)
    
    with col1:
        if numeric_cols:
            st.markdown("**ìˆ˜ì¹˜í˜• ì†ì„±**")
            selected_numeric = st.multiselect(
                "ìˆ˜ì¹˜í˜•",
                numeric_cols,
                help="í‰ê· , í‘œì¤€í¸ì°¨, ìµœì†Œ/ìµœëŒ€ê°’ì´ ê³„ì‚°ë©ë‹ˆë‹¤"
            )
    
    with col2:
        if categorical_cols:
            st.markdown("**ë²”ì£¼í˜• ì†ì„±**")
            selected_categorical = st.multiselect(
                "ë²”ì£¼í˜•",
                categorical_cols,
                help="ê³ ìœ ê°’ ìˆ˜, ì—”íŠ¸ë¡œí”¼, ìµœë¹ˆê°’ì´ ê³„ì‚°ë©ë‹ˆë‹¤"
            )
    
    target_cols = (selected_numeric if 'selected_numeric' in locals() else []) + \
                  (selected_categorical if 'selected_categorical' in locals() else [])
    
    if not target_cols:
        st.warning("í†µê³„ë¥¼ ê³„ì‚°í•  ì†ì„±ì„ ì„ íƒí•´ì£¼ì„¸ìš”")
        return
    
    # ì‹¤í–‰ ì˜µì…˜
    st.markdown("### 3ï¸âƒ£ ì‹¤í–‰ ì˜µì…˜")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # ë°ì´í„° ì¼ê´€ì„± ì²´í¬
        data_check = st.checkbox(
            "ë°ì´í„° ê²€ì¦",
            value=True,
            help="ì‹¤í–‰ ì „ ë°ì´í„° ì¼ê´€ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤"
        )
    
    with col2:
        # ìƒ˜í”Œë§ ì˜µì…˜
        if len(df) > 50000:
            use_sampling = st.checkbox(
                "ìƒ˜í”Œë§ ì‚¬ìš©",
                value=True,
                help=f"ì „ì²´ {len(df):,}í–‰ ì¤‘ ì¼ë¶€ë§Œ ë¶„ì„"
            )
        else:
            use_sampling = False
    
    with col3:
        if use_sampling:
            sample_size = st.number_input(
                "ìƒ˜í”Œ í¬ê¸°",
                min_value=10000,
                max_value=len(df),
                value=min(50000, len(df)),
                step=10000,
                key="ec_sample_size"
            )
    
    # ì‹¤í–‰ ë²„íŠ¼
    if st.button("ğŸ“Š ECë³„ í†µê³„ ê³„ì‚° ì‹¤í–‰", type="primary", use_container_width=True):
        
        # ë°ì´í„° ê²€ì¦
        if data_check:
            with st.spinner("ë°ì´í„° ì¼ê´€ì„± í™•ì¸ ì¤‘..."):
                # í˜„ì¬ dfì™€ ì„¸ì…˜ì˜ dfê°€ ê°™ì€ì§€ í™•ì¸
                if not df.equals(get_analysis_dataframe()):
                    st.error("âš ï¸ ë°ì´í„°ê°€ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.")
                    return
                
                # ì„ íƒí•œ ì»¬ëŸ¼ì´ ëª¨ë‘ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                missing_cols = set(selected_qi + target_cols) - set(df.columns)
                if missing_cols:
                    st.error(f"âš ï¸ ë‹¤ìŒ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_cols}")
                    return
        
        # í†µê³„ ê³„ì‚°
        with st.spinner("ECë³„ í†µê³„ ê³„ì‚° ì¤‘..."):
            try:
                # ìƒ˜í”Œë§ ì ìš©
                analysis_df = df.sample(sample_size) if use_sampling else df
                
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                status_text.text("ë™ì§ˆì§‘í•© ìƒì„± ì¤‘...")
                progress_bar.progress(0.3)
                
                # í†µê³„ ê³„ì‚°
                ec_stats_df = calculate_ec_statistics(
                    df=analysis_df,
                    ec_cols=selected_qi,
                    target_cols=target_cols
                )
                
                progress_bar.progress(0.7)
                status_text.text("ê²°ê³¼ ì •ë¦¬ ì¤‘...")
                
                # ê²°ê³¼ ì €ì¥ (ì¼ê´€ì„±ì„ ìœ„í•´)
                if 'ec_statistics' not in st.session_state:
                    st.session_state.ec_statistics = {}
                
                st.session_state.ec_statistics['latest'] = {
                    'df': ec_stats_df,
                    'ec_cols': selected_qi,
                    'target_cols': target_cols,
                    'timestamp': pd.Timestamp.now(),
                    'sampled': use_sampling,
                    'sample_size': sample_size if use_sampling else len(df)
                }
                
                # ê²°ê³¼ í‘œì‹œ
                display_ec_statistics_results(ec_stats_df, selected_qi, target_cols)
                
                progress_bar.progress(1.0)
                progress_bar.empty()
                status_text.empty()
                
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                progress_bar.empty()
                status_text.empty()

def render_k_anonymity_section(df: pd.DataFrame):
    """k-ìµëª…ì„± ë¶„ì„ ì„¹ì…˜"""
    st.subheader("ğŸ“Š k-ìµëª…ì„± ë¶„ì„")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # ì¤€ì‹ë³„ì ì„ íƒ
        st.markdown("### ì¤€ì‹ë³„ì ì„ íƒ")
        st.info("ì¤€ì‹ë³„ì(Quasi-Identifier)ëŠ” ë‹¨ë…ìœ¼ë¡œëŠ” ê°œì¸ì„ ì‹ë³„í•  ìˆ˜ ì—†ì§€ë§Œ, ì¡°í•©í•˜ë©´ ê°œì¸ì„ ì‹ë³„í•  ê°€ëŠ¥ì„±ì´ ìˆëŠ” ì†ì„±ë“¤ì…ë‹ˆë‹¤.")
        
        # ì»¬ëŸ¼ íƒ€ì…ë³„ë¡œ ë¶„ë¥˜
        numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
        
        # ì¤€ì‹ë³„ì ì„ íƒ UI
        selected_qi = []
        
        if categorical_cols:
            st.markdown("**ë²”ì£¼í˜• ì†ì„±**")
            cat_selected = st.multiselect(
                "ë²”ì£¼í˜• ì¤€ì‹ë³„ì ì„ íƒ",
                categorical_cols,
                help="ì˜ˆ: ì„±ë³„, ì§€ì—­, ì§ì—… ë“±",
                key="cat_qi_select"
            )
            selected_qi.extend(cat_selected)
        
        if numeric_cols:
            st.markdown("**ìˆ˜ì¹˜í˜• ì†ì„±**")
            num_selected = st.multiselect(
                "ìˆ˜ì¹˜í˜• ì¤€ì‹ë³„ì ì„ íƒ",
                numeric_cols,
                help="ì˜ˆ: ë‚˜ì´, ìš°í¸ë²ˆí˜¸ ë“±",
                key="num_qi_select"
            )
            selected_qi.extend(num_selected)
    
    with col2:
        # ë¶„ì„ ì˜µì…˜
        st.markdown("### ë¶„ì„ ì˜µì…˜")
        
        # í‘œë³¸ë¥  ì…ë ¥
        st.markdown("#### ğŸ“Š í‘œë³¸ë¥  ì„¤ì •")
        sample_rate = st.number_input(
            "í‘œë³¸ë¥  (f)",
            min_value=0.001,
            max_value=1.0,
            value=1.0,
            step=0.01,
            format="%.3f",
            help="ì „ì²´ ëª¨ì§‘ë‹¨ ëŒ€ë¹„ í˜„ì¬ ë°ì´í„°ì˜ ë¹„ìœ¨ (1.0 = ì „ì²´ ë°ì´í„°)",
            key="k_anonymity_sample_rate"
        )
        
        # í‘œë³¸ë¥ ì— ë”°ë¥¸ ì„¤ëª…
        if sample_rate < 1.0:
            st.info(f"ğŸ“Œ í˜„ì¬ ë°ì´í„°ëŠ” ì „ì²´ ëª¨ì§‘ë‹¨ì˜ {sample_rate*100:.1f}%ì…ë‹ˆë‹¤")
        else:
            st.info("ğŸ“Œ ì „ì²´ ëª¨ì§‘ë‹¨ ë°ì´í„°ë¡œ ë¶„ì„í•©ë‹ˆë‹¤")
        
        # ìƒ˜í”Œë§ ì˜µì…˜ (ëŒ€ìš©ëŸ‰ ë°ì´í„° ëŒ€ì‘)
        data_size = len(df)
        use_sampling = False  # ğŸ”´ ê¸°ë³¸ê°’ ë¨¼ì € ì„¤ì •
        sample_size = data_size  # ğŸ”´ ê¸°ë³¸ê°’ ì„¤ì •

        if data_size > 500000:
            st.error(f"""
            âš ï¸ **ë§¤ìš° í° ë°ì´í„°ì…‹** ({data_size:,}í–‰)
            
            ê¶Œì¥ì‚¬í•­:
            1. ì¤€ì‹ë³„ìë¥¼ 5ê°œ ì´í•˜ë¡œ ì„ íƒ
            2. ë¨¼ì € ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸ í›„ ì „ì²´ ì‹¤í–‰
            3. ì¹´í…Œê³ ë¦¬ê°€ ë§ì€ ì»¬ëŸ¼ì€ ì œì™¸
            """)
            
            # ëŒ€ìš©ëŸ‰ ë°ì´í„°ì¼ ë•Œ ìƒ˜í”Œë§ ì˜µì…˜ ì œê³µ
            use_sampling = st.checkbox(
                "ìƒ˜í”Œë§ ì‚¬ìš©",
                value=True,
                help=f"ì „ì²´ {data_size:,}í–‰ ì¤‘ ì¼ë¶€ë§Œ ë¶„ì„í•˜ì—¬ ì†ë„ í–¥ìƒ"
            )
            
        elif data_size > 100000:
            st.warning(f"""
            âš ï¸ **ëŒ€ìš©ëŸ‰ ë°ì´í„°** ({data_size:,}í–‰)
            
            ì˜ˆìƒ ì†Œìš” ì‹œê°„: {data_size // 50000}~{data_size // 25000}ë¶„
            """)
            
            # ì¤‘ê°„ í¬ê¸° ë°ì´í„°ì¼ ë•Œë„ ìƒ˜í”Œë§ ì˜µì…˜ ì œê³µ
            use_sampling = st.checkbox(
                "ìƒ˜í”Œë§ ì‚¬ìš©",
                value=True,
                help=f"ì „ì²´ {data_size:,}í–‰ ì¤‘ ì¼ë¶€ë§Œ ë¶„ì„í•˜ì—¬ ì†ë„ í–¥ìƒ"
            )

        # ìƒ˜í”Œë§ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ì—ë§Œ ìƒ˜í”Œ í¬ê¸° ì„¤ì •
        if use_sampling:
            sample_size = st.slider(
                "ìƒ˜í”Œ í¬ê¸°",
                min_value=10000,
                max_value=min(100000, data_size),
                value=50000,
                step=10000,
                format="%dí–‰"
            )
        else:
            use_sampling = False
            sample_size = data_size
        
        # kê°’ ì„ê³„ê°’ ì„¤ì •
        k_threshold = st.number_input(
            "kê°’ ì„ê³„ê°’",
            min_value=2,
            max_value=100,
            value=5,
            help="ì´ ê°’ ë¯¸ë§Œì˜ kë¥¼ ê°€ì§„ ë ˆì½”ë“œëŠ” ìœ„í—˜ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤"
        )
    
    # ë™ì§ˆì§‘í•© ë¯¸ë¦¬ë³´ê¸° ì„¹ì…˜
    if selected_qi:  # ì¤€ì‹ë³„ìê°€ ì„ íƒëœ ê²½ìš°
        with st.expander("ğŸ‘¥ ë™ì§ˆì§‘í•© ë¯¸ë¦¬ë³´ê¸°", expanded=False):
            st.info("""
            **ë™ì§ˆì§‘í•©(Equivalence Class)ì´ë€?**
            ì¤€ì‹ë³„ì ê°’ì´ ëª¨ë‘ ë™ì¼í•œ ë ˆì½”ë“œë“¤ì˜ ê·¸ë£¹ì…ë‹ˆë‹¤.
            ì˜ˆ: ë‚˜ì´(30ëŒ€), ì„±ë³„(ë‚¨), ì§€ì—­(ì„œìš¸) â†’ ì´ ì¡°í•©ì´ ê°™ì€ ëª¨ë“  ì‚¬ëŒë“¤
            """)
            
            # ë¯¸ë¦¬ë³´ê¸° ì˜µì…˜
            preview_option = st.radio(
                "ë¯¸ë¦¬ë³´ê¸° ì˜µì…˜",
                ["ìƒìœ„ 5ê°œ ê·¸ë£¹", "kê°’ì´ ë‚®ì€ ìœ„í—˜ ê·¸ë£¹", "ëœë¤ ìƒ˜í”Œ"],
                horizontal=True
            )
            
            # í‘œì‹œí•  ë ˆì½”ë“œ ìˆ˜
            show_records = st.slider("ê·¸ë£¹ë‹¹ í‘œì‹œí•  ë ˆì½”ë“œ ìˆ˜", 1, 10, 3)
            
            if st.button("ë™ì§ˆì§‘í•© í™•ì¸í•˜ê¸°", key="preview_ec_k"):
                with st.spinner("ë™ì§ˆì§‘í•© ë¶„ì„ ì¤‘..."):
                    # ìƒ˜í”Œë§ ì œê±° - dfë¥¼ ì§ì ‘ ì‚¬ìš©
                    preview_df = df
                    
                    # ë™ì§ˆì§‘í•© ìƒì„±
                    ec_groups = preview_df.groupby(selected_qi)
                    
                    # ê° ê·¸ë£¹ì˜ í¬ê¸° ê³„ì‚°
                    ec_sizes = ec_groups.size().reset_index(name='k')
                    
                    if len(ec_sizes) == 0:
                        st.warning("ë™ì§ˆì§‘í•©ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        # ì •ë ¬ ì˜µì…˜ì— ë”°ë¼ ì •ë ¬
                        if preview_option == "kê°’ì´ ë‚®ì€ ìœ„í—˜ ê·¸ë£¹":
                            ec_sizes = ec_sizes.sort_values('k', ascending=True)
                            top_groups = ec_sizes.head(5)
                        elif preview_option == "ìƒìœ„ 5ê°œ ê·¸ë£¹":
                            ec_sizes = ec_sizes.sort_values('k', ascending=False)
                            top_groups = ec_sizes.head(5)
                        else:  # ëœë¤
                            top_groups = ec_sizes.sample(min(5, len(ec_sizes)))
                        
                        # kê°’ ìˆœì„œ ì •ë ¬ ì˜µì…˜ ì¶”ê°€
                        sort_by_k = st.checkbox("kê°’ ìˆœì„œë¡œ ì •ë ¬", value=True, key="sort_by_k")
                        if sort_by_k and preview_option != "ëœë¤ ìƒ˜í”Œ":
                            ascending = preview_option == "kê°’ì´ ë‚®ì€ ìœ„í—˜ ê·¸ë£¹"
                            top_groups = top_groups.sort_values('k', ascending=ascending)
                
                # ê° ê·¸ë£¹ì˜ ìƒ˜í”Œ í‘œì‹œ
                for idx, (_, group_info) in enumerate(top_groups.iterrows()):
                    st.markdown(f"### ê·¸ë£¹ {idx+1}")
                    
                    # ì¤€ì‹ë³„ì ê°’ í‘œì‹œ
                    qi_values = []
                    for qi in selected_qi:
                        if qi in group_info:
                            qi_values.append(f"{qi}: {group_info[qi]}")
                    
                    st.write(f"**ì¤€ì‹ë³„ì ì¡°í•©**: {', '.join(qi_values)}")
                    st.write(f"**kê°’**: {group_info['k']} (ì´ ì¡°í•©ì„ ê°€ì§„ ì‚¬ëŒ ìˆ˜)")
                    
                    # ìœ„í—˜ë„ í‘œì‹œ
                    if group_info['k'] < k_threshold:
                        st.warning(f"âš ï¸ ìœ„í—˜: kê°’ì´ {k_threshold} ë¯¸ë§Œì…ë‹ˆë‹¤!")
                    else:
                        st.success(f"âœ… ì•ˆì „: kê°’ì´ {k_threshold} ì´ìƒì…ë‹ˆë‹¤.")
                    
                    # í•´ë‹¹ ê·¸ë£¹ì˜ ìƒ˜í”Œ ë ˆì½”ë“œ í‘œì‹œ
                    # ì¤€ì‹ë³„ì ê°’ìœ¼ë¡œ í•„í„°ë§
                    mask = True
                    for qi in selected_qi:
                        mask = mask & (preview_df[qi] == group_info[qi])
                    
                    group_records = preview_df[mask].head(show_records)
                    
                    # ë¯¼ê°í•œ ì •ë³´ëŠ” ê°€ë¦¬ê³  í‘œì‹œ
                    display_cols = selected_qi + [col for col in preview_df.columns 
                                            if col not in selected_qi][:3]  # ì¶”ê°€ë¡œ 3ê°œ ì»¬ëŸ¼ë§Œ
                    
                    st.dataframe(
                        group_records[display_cols],
                        use_container_width=True,
                        hide_index=True
                    )
                    
                    st.markdown("---")
                
                # ì „ì²´ í†µê³„
                st.markdown("### ğŸ“Š ì „ì²´ ë™ì§ˆì§‘í•© í†µê³„")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("ì „ì²´ ê·¸ë£¹ ìˆ˜", f"{len(ec_sizes):,}ê°œ")
                with col2:
                    st.metric("í‰ê·  kê°’", f"{ec_sizes['k'].mean():.1f}")
                with col3:
                    risk_groups = len(ec_sizes[ec_sizes['k'] < k_threshold])
                    st.metric("ìœ„í—˜ ê·¸ë£¹", f"{risk_groups}ê°œ")
                
                # kê°’ ë¶„í¬ ê°„ë‹¨íˆ í‘œì‹œ
                st.markdown("#### kê°’ ë¶„í¬")
                k_dist = ec_sizes['k'].value_counts().sort_index()
                
                # ê°„ë‹¨í•œ íˆìŠ¤í† ê·¸ë¨
                hist_data = []
                for k, count in k_dist.items():
                    if k < k_threshold:
                        hist_data.append({
                            'kê°’': f"k={k}",
                            'ê·¸ë£¹ ìˆ˜': count,
                            'ìƒíƒœ': 'ìœ„í—˜'
                        })
                    else:
                        hist_data.append({
                            'kê°’': f"k={k}" if k <= 10 else f"k>{10}",
                            'ê·¸ë£¹ ìˆ˜': count,
                            'ìƒíƒœ': 'ì•ˆì „'
                        })
                
                hist_df = pd.DataFrame(hist_data)
                st.bar_chart(hist_df.set_index('kê°’')['ê·¸ë£¹ ìˆ˜'])
        
        # EC í†µê³„ ì•ˆë‚´ ë©”ì‹œì§€
        st.info(
            "ğŸ’¡ ë™ì§ˆì§‘í•©ë³„ ìƒì„¸ í†µê³„ë¥¼ ë³´ë ¤ë©´ **'ECë³„ í†µê³„ ë¶„ì„'** íƒ­ì„ ì´ìš©í•˜ì„¸ìš”. "
            "í˜„ì¬ ì„ íƒí•œ ì¤€ì‹ë³„ìê°€ ìë™ìœ¼ë¡œ ì—°ë™ë©ë‹ˆë‹¤."
        )
    
    st.markdown("---")
    
    # k-ìµëª…ì„± ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
    # k-ìµëª…ì„± ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼ ë¶€ë¶„ ê°œì„ 
    if st.button("ğŸ” k-ìµëª…ì„± ë¶„ì„ ì‹¤í–‰", type="primary", disabled=len(selected_qi) == 0):
        
        # ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
        estimated_time = estimate_analysis_time(len(df), len(selected_qi))
        
        if estimated_time > 30:  # 30ì´ˆ ì´ìƒ
            st.warning(f"""
            â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„: **{estimated_time//60}ë¶„ {estimated_time%60}ì´ˆ**
            
            ğŸ’¡ ì‹œê°„ ë‹¨ì¶• ë°©ë²•:
            - ì¤€ì‹ë³„ì ìˆ˜ ì¤„ì´ê¸° (í˜„ì¬: {len(selected_qi)}ê°œ)
            - ìƒ˜í”Œë§ ì‚¬ìš©í•˜ê¸°
            - ì¹´í…Œê³ ë¦¬ê°€ ì ì€ ì»¬ëŸ¼ ì„ íƒ
            """)
            
            if not st.checkbox("ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"):
                st.stop()
        
        # ì‹¤í–‰
        with st.spinner("k-ìµëª…ì„± ë¶„ì„ ì¤‘..."):
            # ìƒ˜í”Œë§ ì ìš©
            if use_sampling and sample_size < len(df): 
                analysis_df = df.sample(n=sample_size)
            else:
                analysis_df = df
            
            # k-ìµëª…ì„± ê³„ì‚°
            try:
                k_value, k_stats = calculate_k_anonymity(
                    analysis_df,
                    selected_qi,
                    k_threshold,
                    sample_rate
                )
                
                # ê²°ê³¼ í‘œì‹œ
                st.markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼")
                
                # ì£¼ìš” ì§€í‘œ í‘œì‹œ (EMP í¬í•¨ 5ê°œ ì»¬ëŸ¼)
                col_a, col_b, col_c, col_d, col_e = st.columns(5)
                
                with col_a:
                    st.metric(
                        "ìµœì†Œ kê°’",
                        f"{k_stats['min_k']}",
                        delta=f"{k_stats['min_k'] - k_threshold}" if k_stats['min_k'] < k_threshold else None,
                        delta_color="inverse"
                    )
                
                with col_b:
                    st.metric(
                        "í‰ê·  kê°’",
                        f"{k_stats['avg_k']:.1f}"
                    )
                
                with col_c:
                    st.metric(
                        "ì¤‘ì•™ê°’",
                        f"{k_stats['median_k']}"
                    )
                
                with col_d:
                    risk_ratio = k_stats['risk_records'] / len(analysis_df) * 100
                    st.metric(
                        "ìœ„í—˜ ë ˆì½”ë“œ",
                        f"{k_stats['risk_records']:,}ê°œ",
                        delta=f"{risk_ratio:.1f}%",
                        delta_color="inverse"
                    )
                
                # EMP ë©”íŠ¸ë¦­ ì¶”ê°€
                with col_e:
                    emp_value = k_stats['emp']
                    emp_percent = emp_value * 100
                    st.metric(
                        "EMP",
                        f"{emp_percent:.2f}%",
                        delta=k_stats['emp_risk_level'],
                        delta_color="inverse" if emp_value > 0.05 else "normal"
                    )
                
                # EMP ìƒì„¸ ì •ë³´ ì¶”ê°€
                st.markdown("### ğŸ¯ EMP (Expected Match Probability) ë¶„ì„")
                emp_col1, emp_col2, emp_col3 = st.columns(3)
                
                with emp_col1:
                    st.info(f"""
                    **EMP ê°’**: {k_stats['emp']:.6f} ({k_stats['emp']*100:.3f}%)
                    **ìœ„í—˜ ìˆ˜ì¤€**: {k_stats['emp_risk_level']}
                    """)
                
                with emp_col2:
                    st.info(f"""
                    **í‘œë³¸ë¥ **: {k_stats['sample_rate']}
                    **í‰ê·  ê°œì¸ ìœ„í—˜ë„**: {k_stats['avg_individual_risk']:.4f}
                    """)
                
                with emp_col3:
                    st.info(f"""
                    **ê³ ìœ„í—˜ ë ˆì½”ë“œ**: {k_stats['high_risk_records']:,}ê°œ
                    **ì „ì²´ ìœ„í—˜ë„ í•©**: {k_stats['total_risk_sum']:.2f}
                    """)
                
                # EMP í•´ì„ ê°€ì´ë“œ
                with st.expander("ğŸ’¡ EMP í•´ì„ ê°€ì´ë“œ", expanded=False):
                    st.markdown("""
                    **EMP(Expected Match Probability)**ëŠ” ë°ì´í„°ì…‹ì—ì„œ ê°œì¸ì´ ì¬ì‹ë³„ë  ê¸°ëŒ€ í™•ë¥ ì…ë‹ˆë‹¤.
                    
                    - **< 1%**: ë§¤ìš° ì•ˆì „ (ì¬ì‹ë³„ ìœ„í—˜ ë§¤ìš° ë‚®ìŒ)
                    - **1-5%**: ì•ˆì „ (ì¬ì‹ë³„ ìœ„í—˜ ë‚®ìŒ)
                    - **5-10%**: ì£¼ì˜ í•„ìš” (ì¤‘ê°„ ìˆ˜ì¤€ ìœ„í—˜)
                    - **10-20%**: ìœ„í—˜ (ì¬ì‹ë³„ ìœ„í—˜ ë†’ìŒ)
                    - **> 20%**: ë§¤ìš° ìœ„í—˜ (ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”)
                    
                    **ê³„ì‚° ë°©ë²•**: Skinner-Elliot ëª¨ë¸ ê¸°ë°˜
                    - ê°œë³„ ìœ„í—˜ë„ = 1 / (í‘œë³¸ë¥  Ã— ECí¬ê¸°)
                    - EMP = (í‘œë³¸ë¥  / ì „ì²´ë ˆì½”ë“œìˆ˜) Ã— Î£ê°œë³„ìœ„í—˜ë„
                    """)
                
                # kê°’ ë¶„í¬ ì‹œê°í™”
                st.markdown("### ğŸ“ˆ kê°’ ë¶„í¬")
                create_k_distribution_chart(k_stats['k_distribution'], k_threshold)
                
                # ìœ„í—˜ ë ˆì½”ë“œ ìƒì„¸
                if k_stats['risk_records'] > 0:
                    with st.expander(f"âš ï¸ ìœ„í—˜ ë ˆì½”ë“œ ìƒì„¸ (k < {k_threshold})", expanded=False):
                        risk_df = k_stats['risk_records_detail']
                        st.dataframe(
                            risk_df.head(100),  # ìµœëŒ€ 100ê°œë§Œ í‘œì‹œ
                            use_container_width=True
                        )
                        
                        if len(risk_df) > 100:
                            st.info(f"ì „ì²´ {len(risk_df)}ê°œ ì¤‘ ìƒìœ„ 100ê°œë§Œ í‘œì‹œë©ë‹ˆë‹¤.")
                
                # ë¶„ì„ ì •ë³´ ì €ì¥ (ë‹¤ë¥¸ íƒ­ì—ì„œ ì‚¬ìš©)
                if 'privacy_analysis' not in st.session_state:
                    st.session_state.privacy_analysis = {}
                
                st.session_state.privacy_analysis['k_anonymity'] = {
                    'quasi_identifiers': selected_qi,
                    'k_value': k_value,
                    'k_stats': k_stats,
                    'threshold': k_threshold,
                    'sampled': use_sampling,
                    'sample_rate': sample_rate,
                    'emp': k_stats['emp'],
                    'emp_risk_level': k_stats['emp_risk_level']
                }
                
                st.success("âœ… k-ìµëª…ì„± ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                
            except Exception as e:
                st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    elif len(selected_qi) == 0:
        st.info("ğŸ‘† ì¤€ì‹ë³„ìë¥¼ ì„ íƒí•˜ê³  ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”.")


import time

def calculate_k_anonymity_with_timing(df, quasi_identifiers, k_threshold, sample_rate):
    """ì‹œê°„ ì¸¡ì •ê³¼ í•¨ê»˜ k-ìµëª…ì„± ê³„ì‚°"""
    
    start_time = time.time()
    step_times = {}
    
    # ê° ë‹¨ê³„ë³„ ì‹œê°„ ì¸¡ì •
    step_start = time.time()
    group_sizes = df.groupby(quasi_identifiers).size().reset_index(name='count')
    step_times['groupby'] = time.time() - step_start
    
    # ... ë‚˜ë¨¸ì§€ ê³„ì‚° ...
    
    total_time = time.time() - start_time
    
    # ì„±ëŠ¥ ì •ë³´ í‘œì‹œ
    with st.expander("â±ï¸ ì„±ëŠ¥ ë¶„ì„", expanded=False):
        st.write(f"ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
        for step, duration in step_times.items():
            st.write(f"- {step}: {duration:.2f}ì´ˆ ({duration/total_time*100:.1f}%)")
    
    return k_value, k_stats


def calculate_k_anonymity(
        df: pd.DataFrame,
        quasi_identifiers: List[str],
        k_threshold: int = 5,
        sample_rate: float = 1.0
) -> Tuple[int, Dict]:
    """
    ìµœì í™”ëœ k-ìµëª…ì„± ë° EMP ê³„ì‚°
    """
    # ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ placeholder
    progress_placeholder = st.empty()
    progress_bar = st.progress(0)
    
    try:
        # 1) ë™ì§ˆì§‘í•© í¬ê¸° ê³„ì‚° (10%)
        progress_placeholder.text("ë™ì§ˆì§‘í•© ìƒì„± ì¤‘...")
        progress_bar.progress(0.1)
        
        group_sizes = (
            df.groupby(quasi_identifiers)
              .size()
              .reset_index(name='count')
        )
        
        k_value = int(group_sizes['count'].min())
        
        # 2) ìœ„í—˜ ë ˆì½”ë“œ ì¶”ì¶œ (20%)
        progress_placeholder.text("ìœ„í—˜ ë ˆì½”ë“œ ë¶„ì„ ì¤‘...")
        progress_bar.progress(0.2)
        
        risk_ec = group_sizes[group_sizes['count'] < k_threshold][quasi_identifiers]
        
        if len(risk_ec) > 0:
            risk_records_detail = df.merge(
                risk_ec,
                on=quasi_identifiers,
                how='inner'
            )
        else:
            risk_records_detail = pd.DataFrame()
        
        # 3) EMP ê³„ì‚° (íš¨ìœ¨ì ì¸ ë°©ë²•ë§Œ ì‚¬ìš©) (50%)
        progress_placeholder.text("EMP ìœ„í—˜ë„ ê³„ì‚° ì¤‘...")
        progress_bar.progress(0.5)
        
        n = len(df)
        
        # ğŸ”´ ìµœì í™”: merge í•œ ë²ˆë§Œ ìˆ˜í–‰
        df_with_ec_size = df.merge(
            group_sizes.rename(columns={'count': 'ec_size'}),
            on=quasi_identifiers,
            how='left'
        )
        
        # ë²¡í„°í™”ëœ ê³„ì‚°
        df_with_ec_size['risk_i'] = 1 / (sample_rate * df_with_ec_size['ec_size'])
        df_with_ec_size['risk_i'] = df_with_ec_size['risk_i'].clip(upper=1)
        
        total_risk = df_with_ec_size['risk_i'].sum()
        emp = (sample_rate / n) * total_risk
        
        # 4) í†µê³„ ê³„ì‚° (80%)
        progress_placeholder.text("í†µê³„ ì •ë¦¬ ì¤‘...")
        progress_bar.progress(0.8)
        
        k_stats = {
            'min_k': k_value,
            'max_k': int(group_sizes['count'].max()),
            'avg_k': float(group_sizes['count'].mean()),
            'median_k': int(group_sizes['count'].median()),
            'k_distribution': group_sizes['count']
                              .value_counts()
                              .sort_index()
                              .to_dict(),
            'risk_records': len(risk_records_detail),
            'risk_records_detail': risk_records_detail,
            'emp': emp,
            'sample_rate': sample_rate,
            'total_risk_sum': total_risk,
            'avg_individual_risk': total_risk / n,
            'high_risk_records': len(df_with_ec_size[df_with_ec_size['risk_i'] >= 0.5]),
            'emp_risk_level': get_emp_risk_level(emp)
        }
        
        # ì™„ë£Œ (100%)
        progress_bar.progress(1.0)
        progress_placeholder.text("ë¶„ì„ ì™„ë£Œ!")
        
        # ì ì‹œ í›„ progress bar ì œê±°
        time.sleep(0.5)
        progress_bar.empty()
        progress_placeholder.empty()
        
        return k_value, k_stats
        
    except Exception as e:
        progress_bar.empty()
        progress_placeholder.empty()
        raise e


def preview_equivalence_classes(df: pd.DataFrame, selected_qi: List[str], 
                               preview_option: str, k_threshold: int):
    """ìµœì í™”ëœ ë™ì§ˆì§‘í•© ë¯¸ë¦¬ë³´ê¸°"""
    
    with st.spinner("ë™ì§ˆì§‘í•© ë¶„ì„ ì¤‘..."):
        # Progress bar ì¶”ê°€
        progress = st.progress(0)
        
        # 1. EC ê³„ì‚° (ìºì‹± í™œìš©)
        @st.cache_data
        def compute_ec_sizes(_df, qi_list):
            return _df.groupby(qi_list).size().reset_index(name='k')
        
        progress.progress(0.3)
        ec_sizes = compute_ec_sizes(df, selected_qi)
        
        progress.progress(0.6)
        
        # 2. ì •ë ¬ (ë²¡í„°í™”)
        if preview_option == "kê°’ì´ ë‚®ì€ ìœ„í—˜ ê·¸ë£¹":
            top_groups = ec_sizes.nsmallest(5, 'k')
        elif preview_option == "ìƒìœ„ 5ê°œ ê·¸ë£¹":
            top_groups = ec_sizes.nlargest(5, 'k')
        else:
            top_groups = ec_sizes.sample(min(5, len(ec_sizes)))
        
        progress.progress(1.0)
        progress.empty()
        
        return ec_sizes, top_groups
    
# ğŸ”´ EMP ìœ„í—˜ ìˆ˜ì¤€ í‰ê°€ í•¨ìˆ˜ ì¶”ê°€
def get_emp_risk_level(emp: float) -> str:
    """EMP ê°’ì— ë”°ë¥¸ ìœ„í—˜ ìˆ˜ì¤€ í‰ê°€"""
    if emp < 0.01:
        return "ë§¤ìš° ë‚®ìŒ"
    elif emp < 0.05:
        return "ë‚®ìŒ"
    elif emp < 0.1:
        return "ì¤‘ê°„"
    elif emp < 0.2:
        return "ë†’ìŒ"
    else:
        return "ë§¤ìš° ë†’ìŒ"

def create_k_distribution_chart(k_distribution: Dict[int, int], threshold: int):
    """kê°’ ë¶„í¬ ì°¨íŠ¸ ìƒì„± (Streamlit ë‚´ì¥ ì°¨íŠ¸ ì‚¬ìš©)"""
    # ë°ì´í„° ì¤€ë¹„
    k_values = list(k_distribution.keys())
    counts = list(k_distribution.values())
    
    # DataFrameìœ¼ë¡œ ë³€í™˜
    chart_data = pd.DataFrame({
        'kê°’': k_values,
        'ê·¸ë£¹ ìˆ˜': counts,
        'ìƒíƒœ': ['ìœ„í—˜' if k < threshold else 'ì•ˆì „' for k in k_values]
    })
    
    # Streamlit ì°¨íŠ¸
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # ë§‰ëŒ€ ì°¨íŠ¸
        st.bar_chart(
            data=chart_data.set_index('kê°’')['ê·¸ë£¹ ìˆ˜'],
            height=400
        )
    
    with col2:
        # í†µê³„ ì •ë³´
        st.metric("ì„ê³„ê°’", f"k = {threshold}")
        st.metric("ìœ„í—˜ ê·¸ë£¹", f"{len([k for k in k_values if k < threshold])}ê°œ")
        st.metric("ì•ˆì „ ê·¸ë£¹", f"{len([k for k in k_values if k >= threshold])}ê°œ")
    
    # ì¶”ê°€ ì •ë³´
    if any(k < threshold for k in k_values):
        st.warning(f"âš ï¸ k < {threshold}ì¸ ê·¸ë£¹ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
    else:
        st.success(f"âœ… ëª¨ë“  ê·¸ë£¹ì´ k â‰¥ {threshold}ë¥¼ ë§Œì¡±í•©ë‹ˆë‹¤.")

def render_utility_evaluation_section(_: pd.DataFrame):
    """ìœ ìš©ì„± í‰ê°€ íƒ­ â€“ ê°œì„ ëœ ë²„ì „"""
    st.subheader("ğŸ“ˆ ìœ ìš©ì„± í‰ê°€")
    
    # ì§€í‘œ ë©”íƒ€ ì •ë³´ (ê°œì„ ëœ ì„ê³„ê°’)
    METRIC_INFO = {
        'U1': {
            'name': 'í‰ê· ê°’ ì°¨ì´',
            'desc': 'ë‘ ë°ì´í„°ì…‹ í‰ê· ê°’ì´ ì–¼ë§ˆë‚˜ ë‹¤ë¥¸ì§€ ì¸¡ì • (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)',
            'thresholds': {'excellent': 0.05, 'good': 0.1, 'fair': 0.5},
            'lower_better': True
        },
        'U2': {
            'name': 'ìƒê´€ê³„ìˆ˜ ë³´ì¡´',
            'desc': 'ì›ë³¸Â·ë¹„ì‹ë³„ ìƒê´€ê³„ìˆ˜ ì°¨ì´ í‰ê·  (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)',
            'thresholds': {'excellent': 0.01, 'good': 0.05, 'fair': 0.1},
            'lower_better': True
        },
        'U3': {
            'name': 'ì½”ì‚¬ì¸ ìœ ì‚¬ë„',
            'desc': 'ë²¡í„° ìœ ì‚¬ë„ í‰ê·  (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)',
            'thresholds': {'excellent': 0.99, 'good': 0.95, 'fair': 0.9},
            'lower_better': False
        },
        'U4': {
            'name': 'ì •ê·œí™” ê±°ë¦¬',
            'desc': 'ì •ê·œí™” SSE í•© (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)',
            'thresholds': {'excellent': 0.01, 'good': 0.05, 'fair': 0.1},
            'lower_better': True
        },
        'U5': {
            'name': 'í‘œì¤€í™” ê±°ë¦¬',
            'desc': 'í‘œì¤€í™” SSE í•© (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)',
            'thresholds': {'excellent': 0.1, 'good': 0.5, 'fair': 1.0},
            'lower_better': True
        },
        'U6': {
            'name': 'ë™ì§ˆì§‘í•© ë¶„ì‚°',
            'desc': 'ë™ì§ˆì§‘í•© ë‚´ ë¯¼ê°ê°’ ë¶„ì‚° í‰ê·  (ë‚®ì„ìˆ˜ë¡ ì •ë³´ ìœ ì§€)',
            'thresholds': {'excellent': 0.5, 'good': 1.0, 'fair': 2.0},
            'lower_better': True
        },
        'U7': {
            'name': 'ì •ê·œí™” ì§‘í•©í¬ê¸°',
            'desc': '(N/N_EC)/k : ë™ì§ˆì§‘í•© í¬ê¸° ì§€í‘œ (ë‚®ì„ìˆ˜ë¡ ì•ˆì „)',
            'thresholds': {'excellent': 1.0, 'good': 2.0, 'fair': 5.0},
            'lower_better': True
        },
        'U8': {
            'name': 'ë¹„ê· ì¼ ì—”íŠ¸ë¡œí”¼',
            'desc': 'ë³€ê²½ ë ˆì½”ë“œ ì—”íŠ¸ë¡œí”¼ (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì›ë³¸ê³¼ ìœ ì‚¬)',
            'thresholds': {'excellent': 0.1, 'good': 0.3, 'fair': 0.5},
            'lower_better': True
        },
        'U9': {
            'name': 'ìµëª…í™”ìœ¨',
            'desc': 'ë¹„ì‹ë³„ ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ë‚¨ì•˜ëŠ”ì§€ (%) (ë†’ì„ìˆ˜ë¡ í™œìš© â†‘)',
            'thresholds': {'excellent': 95, 'good': 90, 'fair': 80},
            'lower_better': False
        },
    }
    
    # ë„ì›€ë§ í† ê¸€
    show_help = st.toggle("ğŸ‘¶ ì²˜ìŒì´ë¼ë©´ ë„ì›€ë§ ë³´ê¸°", value=False)
    if show_help:
        st.info("**ìœ ìš©ì„±(U) ì§€í‘œë€?**\n\n" + 
                "\n".join([f"â€¢ **{k} ({v['name']})** : {v['desc']}" 
                          for k, v in METRIC_INFO.items()]))

    # 1. ë°ì´í„° ì¡´ì¬ í™•ì¸
    if 'df' not in st.session_state or 'df_processed' not in st.session_state:
        st.warning("ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê³  ë¹„ì‹ë³„í™”ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        return

    orig_df = st.session_state.df
    proc_df = st.session_state.df_processed

    # 2. ë¬´ì¡°ê±´ ë³€í™˜ëœ ë°ì´í„° íƒ€ì… ì‚¬ìš©
    st.info("ğŸ“Œ ë³€í™˜ëœ ë°ì´í„°ì˜ íƒ€ì…ì„ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.")
    
    # ë³€í™˜ëœ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ì»¬ëŸ¼ ë¶„ë¥˜
    numeric_cols = proc_df.select_dtypes(include='number').columns.tolist()
    all_cols = proc_df.columns.tolist()

    # 3. í‰ê°€ ëŒ€ìƒ ì»¬ëŸ¼
    if 'util_cols' not in st.session_state:
        st.session_state.util_cols = numeric_cols

    st.markdown("### â‘  í‰ê°€ ëŒ€ìƒ ì»¬ëŸ¼")
    left, right = st.columns([3, 1])
    with right:
        if st.button("ìˆ«ìí˜•ë§Œ"):
            st.session_state.util_cols = numeric_cols
            st.rerun()

        if st.button("ì „ì²´"):
            st.session_state.util_cols = all_cols
            st.rerun()

        if st.button("ì´ˆê¸°í™”"):
            st.session_state.util_cols = []
            st.rerun()

    with left:
        sel_cols = st.multiselect(
            "ì»¬ëŸ¼ ì„ íƒ", all_cols,
            default=st.session_state.util_cols, key="util_cols"
        )
    
    if not sel_cols:
        st.info("ì»¬ëŸ¼ì„ í•œ ê°œ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.")
        return
    sel_num = [c for c in sel_cols if c in numeric_cols]

    # UtilityMetrics ì¤€ë¹„
    from modules.privacy_metrics.utility_metrics import UtilityMetrics
    utility_analyzer = UtilityMetrics(orig_df, proc_df) 

    # 4. ì§€í‘œ ì„ íƒ & QI ì˜µì…˜
    st.markdown("### â‘¡ ì§€í‘œ ì„ íƒ")
    
    metrics = st.multiselect(
        "ì‹¤í–‰í•  ì§€í‘œ", list(METRIC_INFO.keys()),
        default=['U1', 'U2', 'U9'],
        format_func=lambda m: f"{m} â€“ {METRIC_INFO[m]['name']}"
    )

    # ì„ íƒí•œ ì§€í‘œ ì„¤ëª… íŒ¨ë„
    if metrics:
        with st.container():
            st.markdown("#### ì„ íƒ ì§€í‘œ ì„¤ëª…")
            for m in metrics:
                st.markdown(f"**{m} â€“ {METRIC_INFO[m]['name']}**  \n"
                            f"{METRIC_INFO[m]['desc']}")
    
    qi_cols, sens_attr = [], None
    if any(m in metrics for m in ('U6', 'U7')):
        with st.expander("ğŸ” QIÂ·ë¯¼ê°ì†ì„±", expanded=True):
            qi_cols = st.multiselect("ì¤€ì‹ë³„ì(QI)", options=sel_cols)
            if qi_cols:
                cand = [c for c in sel_num if c not in qi_cols]
                if cand:
                    sens_attr = st.selectbox("ë¯¼ê°ì†ì„±", cand)

    # 5. ìƒ˜í”Œë§
    st.markdown("### â‘¢ ìƒ˜í”Œë§")
    use_samp = st.toggle("ìƒ˜í”Œë§ ì‚¬ìš©", value=True)
    samp_rows = st.slider(
        "ìƒ˜í”Œ í–‰ ìˆ˜", 10_000, min(1_000_000, len(orig_df)),
        100_000, step=10_000, disabled=not use_samp, format="%d í–‰"
    )
    analysis_df = orig_df.sample(samp_rows, random_state=42) if use_samp and samp_rows < len(orig_df) else orig_df

    # 6. ì‹¤í–‰
    st.markdown("### â‘£ í‰ê°€ ì‹¤í–‰")
    if st.button("ğŸš€ ì„ íƒí•œ ì§€í‘œ ì‹¤í–‰", type="primary"):
        run_id = uuid.uuid4().hex[:8]
        summary, detail_results = [], {}
        prog = st.progress(0.0)
        total = len(metrics)

        # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— í–‰ ì¶”ê°€í•˜ëŠ” í—¬í¼ (ê°œì„ )
        def push(metric: str, res: dict, used_cols: list):
            """summaryÂ·detail ë‘ ê³³ì— ê²°ê³¼ë¥¼ ì €ì¥"""
            metric_info = METRIC_INFO[metric]
            
            # U2 ìƒê´€ê³„ìˆ˜ëŠ” íŠ¹ë³„ ì²˜ë¦¬
            if metric == 'U2' and res.get('status') == 'success':
                # ì „ì²´ ì ìˆ˜
                score = res.get('total_score', 0)
                summary.append({
                    'ì§€í‘œ': metric,
                    'ì§€í‘œëª…': metric_info['name'],
                    'ì»¬ëŸ¼': "ì „ì²´ ìƒê´€ê³„ìˆ˜",
                    'ì ìˆ˜': round(score, 4) if isinstance(score, (int, float)) else score,
                    'í‰ê°€': get_score_badge(metric, score, METRIC_INFO)
                })
                
                # ê°œë³„ ìŒ ê²°ê³¼
                if 'pair_results' in res:
                    for pair, pair_res in res['pair_results'].items():
                        summary.append({
                            'ì§€í‘œ': metric,
                            'ì§€í‘œëª…': metric_info['name'],
                            'ì»¬ëŸ¼': pair,
                            'ì ìˆ˜': round(pair_res['difference'], 4),
                            'í‰ê°€': get_score_badge(metric, pair_res['difference'], METRIC_INFO)
                        })
            
            # ì»¬ëŸ¼ë³„ ì ìˆ˜ë¥¼ ë¶„í•´í•´ì„œ ë³´ì—¬ì¤˜ì•¼ í•˜ëŠ” ì§€í‘œ
            elif metric in ('U1', 'U3', 'U4', 'U5') and res.get('status') == 'success':
                for col, det in res['column_results'].items():
                    if 'error' in det:
                        continue
                    val = det.get('difference') or det.get('cosine_similarity') \
                          or det.get('normalized_sse') or det.get('sse')
                    summary.append({
                        'ì§€í‘œ': metric,
                        'ì§€í‘œëª…': metric_info['name'],
                        'ì»¬ëŸ¼': col,
                        'ì ìˆ˜': round(val, 4) if isinstance(val, (int, float)) else val,
                        'í‰ê°€': get_score_badge(metric, val, METRIC_INFO)
                    })
            else:
                score = res.get('total_score') or res.get('average_score')
                summary.append({
                    'ì§€í‘œ': metric,
                    'ì§€í‘œëª…': metric_info['name'],
                    'ì»¬ëŸ¼': ", ".join(used_cols) if used_cols else '-',
                    'ì ìˆ˜': round(score, 4) if isinstance(score, (int, float)) else score,
                    'í‰ê°€': get_score_badge(metric, score, METRIC_INFO)
                })
            detail_results[metric] = res

        # ì„ íƒí•œ ì§€í‘œ ìˆœì°¨ ì‹¤í–‰
        for i, m in enumerate(metrics, 1):
            prog.progress(i / total, text=f"{m} ê³„ì‚° ì¤‘â€¦")

            if m == 'U1':
                push(m, utility_analyzer.calculate_u1_ma(sel_num), sel_num)
            elif m == 'U2':
                push(m, utility_analyzer.calculate_u2_mc(sel_num), sel_num)
            elif m == 'U3':
                push(m, utility_analyzer.calculate_u3_cs(sel_num), sel_num)
            elif m == 'U4':
                push(m, utility_analyzer.calculate_u4_ned(sel_num), sel_num)
            elif m == 'U5':
                push(m, utility_analyzer.calculate_u5_sed(sel_num), sel_num)
            elif m == 'U6' and qi_cols and sens_attr:
                push(m, utility_analyzer.calculate_u6_md_ecm(qi_cols, sens_attr), [sens_attr])
            elif m == 'U7' and qi_cols:
                push(m, utility_analyzer.calculate_u7_na_ecsm(qi_cols), qi_cols)
            elif m == 'U8':
                push(m, utility_analyzer.calculate_u8_nuem(sel_num), sel_num)
            elif m == 'U9':
                push(m, utility_analyzer.calculate_u9_ar(), [])

        prog.empty()

        # íˆìŠ¤í† ë¦¬ ì„¸ì…˜ ìŠ¤í† ë¦¬ì§€
        st.session_state.setdefault('util_history', []).append({
            'id':     run_id,
            'time':   time.strftime("%H:%M:%S"),
            'rows':   len(analysis_df),
            'summary': summary,
            'detail':  detail_results,
        })

    # 7. ê²°ê³¼ í‘œì‹œ (ê°œì„ )
    if st.session_state.get("util_history"):
        latest = st.session_state.util_history[-1]
        st.markdown(f"### â‘¤ ê²°ê³¼ ìš”ì•½ ({latest['time']})")

        # A. ì£¼ìš” ë©”íŠ¸ë¦­ ì¹´ë“œ
        card_metrics = ["U1", "U2", "U3", "U9"]
        cols = st.columns(len(card_metrics))

        for col, m in zip(cols, card_metrics):
            # í•´ë‹¹ ì§€í‘œì˜ ì²« ë²ˆì§¸ ê²°ê³¼ ì°¾ê¸°
            row = next((r for r in latest["summary"] if r["ì§€í‘œ"] == m), None)
            if not row:
                col.empty()
                continue

            # ìƒ‰ìƒê³¼ ì•„ì´ì½˜ ê²°ì •
            badge = row['í‰ê°€']
            emoji = badge.split()[0] if badge else "âšª"
            
            col.metric(
                label=f"{m} - {METRIC_INFO[m]['name']}",
                value=f"{row['ì ìˆ˜']} {emoji}",
                help=badge
            )

        # B. ê°œì„ ëœ ìš”ì•½í‘œ
        df_sum = pd.DataFrame(latest["summary"])
        
        # ì»¬ëŸ¼ ìˆœì„œ ì¡°ì •
        display_cols = ['ì§€í‘œ', 'ì§€í‘œëª…', 'ì»¬ëŸ¼', 'ì ìˆ˜', 'í‰ê°€']
        df_sum = df_sum[display_cols]
        
        # ìŠ¤íƒ€ì¼ ì ìš©
        styled_df = df_sum.style.apply(lambda x: [
            'background-color: #e8f5e9' if 'ğŸŸ¢' in str(v) else
            'background-color: #fff3e0' if 'ğŸŸ¡' in str(v) else
            'background-color: #ffebee' if 'ğŸ”´' in str(v) else ''
            for v in x
        ], axis=1)
        
        st.dataframe(styled_df, hide_index=True, use_container_width=True)

        # C. ìƒì„¸ ê²°ê³¼
        with st.expander("ğŸ” ìƒì„¸ ê²°ê³¼ ë³´ê¸°"):
            for metric in latest["detail"]:
                st.markdown(f"#### {metric} - {METRIC_INFO[metric]['name']}")
                st.json(latest["detail"][metric])

        # D. ë‹¤ìš´ë¡œë“œ
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                "â¬‡ï¸ ìš”ì•½ CSV",
                df_sum.to_csv(index=False, encoding="utf-8-sig").encode(),
                "utility_summary.csv",
            )
        with col2:
            st.download_button(
                "â¬‡ï¸ ìƒì„¸ JSON",
                json.dumps(latest["detail"], ensure_ascii=False, indent=2).encode("utf-8"),
                "utility_detail.json",
                mime="application/json",
            )

        # E. ì‹¤í–‰ íˆìŠ¤í† ë¦¬
        with st.expander("ğŸ•‘ ì‹¤í–‰ íˆìŠ¤í† ë¦¬"):
            for h in reversed(st.session_state.util_history):
                if st.button(f"{h['time']} ({h['rows']} rows)", key=h["id"]):
                    # ì„ íƒí•œ íˆìŠ¤í† ë¦¬ë¥¼ ë§¨ ë’¤ë¡œ ë³´ë‚´ê³  ë‹¤ì‹œ ë Œë”
                    st.session_state.util_history.append(
                        st.session_state.util_history.pop(
                            st.session_state.util_history.index(h)
                        )
                    )
                    st.rerun()

def calculate_ec_statistics(df: pd.DataFrame, ec_cols: List[str], target_cols: List[str], 
                          ec_selection: List[Dict] = None) -> pd.DataFrame:
    """
    ECë³„ í†µê³„ ê³„ì‚°
    
    Args:
        df: ì „ì²´ ë°ì´í„°í”„ë ˆì„
        ec_cols: EC(ë™ì§ˆì§‘í•©) ê¸°ì¤€ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        target_cols: í†µê³„ ì‚°ì¶œ ëŒ€ìƒ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        ec_selection: ì„ íƒí•œ EC ì¡°í•© (ì˜µì…˜)
    
    Returns:
        ECë³„ í†µê³„ê°€ í¬í•¨ëœ DataFrame
    """
    import scipy.stats as stats
    
    # 1. ê²°ì¸¡ê°’ ì²˜ë¦¬ ì˜µì…˜
    df_clean = df.copy()
    
    # 2. ECë³„ ê·¸ë£¹í™”
    ec_groups = df_clean.groupby(ec_cols)
    
    # 3. ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸
    results = []
    
    # 4. ê° ECì— ëŒ€í•´ í†µê³„ ê³„ì‚°
    for ec_values, group in ec_groups:
        row_data = {}
        
        # EC ì‹ë³„ì ì¶”ê°€
        if isinstance(ec_values, tuple):
            for i, col in enumerate(ec_cols):
                row_data[col] = ec_values[i]
        else:
            row_data[ec_cols[0]] = ec_values
        
        # EC í¬ê¸°
        row_data['EC_SIZE'] = len(group)
        
        # ê° target columnì— ëŒ€í•œ í†µê³„
        for target_col in target_cols:
            if target_col not in group.columns:
                continue
                
            col_data = group[target_col].dropna()
            
            # ë°ì´í„° íƒ€ì… í™•ì¸
            if pd.api.types.is_numeric_dtype(col_data):
                # ìˆ˜ì¹˜í˜• í†µê³„
                row_data[f'{target_col}_mean'] = col_data.mean() if len(col_data) > 0 else None
                row_data[f'{target_col}_std'] = col_data.std() if len(col_data) > 1 else None
                row_data[f'{target_col}_min'] = col_data.min() if len(col_data) > 0 else None
                row_data[f'{target_col}_max'] = col_data.max() if len(col_data) > 0 else None
                row_data[f'{target_col}_count'] = len(col_data)
            else:
                # ë²”ì£¼í˜• í†µê³„
                row_data[f'{target_col}_nunique'] = col_data.nunique()
                
                # ìµœë¹ˆê°’
                if len(col_data) > 0:
                    mode_result = col_data.mode()
                    row_data[f'{target_col}_mode'] = mode_result[0] if len(mode_result) > 0 else None
                    row_data[f'{target_col}_mode_ratio'] = (col_data == row_data[f'{target_col}_mode']).sum() / len(col_data)
                
                # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
                value_counts = col_data.value_counts()
                if len(value_counts) > 1:
                    probabilities = value_counts / len(col_data)
                    entropy = -sum(p * np.log2(p) for p in probabilities if p > 0)
                    row_data[f'{target_col}_entropy'] = entropy
                else:
                    row_data[f'{target_col}_entropy'] = 0.0
        
        results.append(row_data)
    
    # DataFrameìœ¼ë¡œ ë³€í™˜
    result_df = pd.DataFrame(results)
    
    # EC_SIZEë¡œ ì •ë ¬
    result_df = result_df.sort_values('EC_SIZE', ascending=True)
    
    # EC ì„ íƒ í•„í„°ë§ (ì˜µì…˜)
    if ec_selection:
        # ì„ íƒí•œ ECë§Œ í•„í„°ë§
        mask = pd.Series([False] * len(result_df))
        for selection in ec_selection:
            condition = pd.Series([True] * len(result_df))
            for col, val in selection.items():
                if col in result_df.columns:
                    condition &= (result_df[col] == val)
            mask |= condition
        result_df = result_df[mask]
    
    return result_df

def display_ec_statistics_results(ec_stats_df: pd.DataFrame, selected_qi: List[str], target_cols: List[str]):
    """EC í†µê³„ ê²°ê³¼ í‘œì‹œ (ìµœì í™”)"""
    
    st.success(f"âœ… {len(ec_stats_df)}ê°œ ECì— ëŒ€í•œ í†µê³„ ê³„ì‚° ì™„ë£Œ!")
    
    # ìš”ì•½ ì •ë³´
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì „ì²´ EC ìˆ˜", f"{len(ec_stats_df):,}ê°œ")
    with col2:
        avg_size = ec_stats_df['EC_SIZE'].mean()
        st.metric("í‰ê·  EC í¬ê¸°", f"{avg_size:.1f}")
    with col3:
        total_records = ec_stats_df['EC_SIZE'].sum()
        st.metric("ì´ ë ˆì½”ë“œ ìˆ˜", f"{total_records:,}")
    
    # í‘œì‹œ ì˜µì…˜
    st.markdown("### ğŸ“Š ê²°ê³¼ í‘œì‹œ ì˜µì…˜")
    col1, col2 = st.columns(2)
    
    with col1:
        # í‘œì‹œí•  í–‰ ìˆ˜ ì œí•œ
        max_rows = st.slider(
            "í‘œì‹œí•  ìµœëŒ€ EC ìˆ˜",
            min_value=10,
            max_value=min(1000, len(ec_stats_df)),
            value=min(100, len(ec_stats_df)),
            step=10
        )
    
    with col2:
        # ì •ë ¬ ì˜µì…˜
        sort_by = st.selectbox(
            "ì •ë ¬ ê¸°ì¤€",
            ['EC_SIZE'] + [col for col in ec_stats_df.columns if col.endswith('_entropy')],
            format_func=lambda x: x.replace('_', ' ').title()
        )
        sort_order = st.radio("ì •ë ¬ ìˆœì„œ", ["ì˜¤ë¦„ì°¨ìˆœ", "ë‚´ë¦¼ì°¨ìˆœ"], horizontal=True)
    
    # í…Œì´ë¸” í‘œì‹œ
    st.markdown("### ğŸ“‹ ECë³„ í†µê³„ í…Œì´ë¸”")
    
    # ì •ë ¬ ì ìš©
    display_df = ec_stats_df.sort_values(
        sort_by, 
        ascending=(sort_order == "ì˜¤ë¦„ì°¨ìˆœ")
    ).head(max_rows)
    
    # ì»¬ëŸ¼ ì„ íƒ
    display_cols = selected_qi + ['EC_SIZE']
    for target_col in target_cols:
        stat_cols = [col for col in display_df.columns if col.startswith(f'{target_col}_')]
        display_cols.extend(stat_cols)
    
    # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
    st.dataframe(
        display_df[display_cols],
        use_container_width=True,
        height=400
    )
    
    # ë‹¤ìš´ë¡œë“œ
    csv = ec_stats_df.to_csv(index=False, encoding='utf-8-sig')
    st.download_button(
        label="ğŸ“¥ ì „ì²´ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
        data=csv.encode('utf-8-sig'),
        file_name=f"ec_statistics_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv"
    )
    
    # ì‹œê°í™”ëŠ” ì„ íƒì ìœ¼ë¡œ
    if st.checkbox("ğŸ“ˆ ì—”íŠ¸ë¡œí”¼ ì‹œê°í™” ë³´ê¸°", value=False, key="show_entropy_viz_main"):
        display_entropy_visualization(display_df)


# ì‚¬ìš©ìì—ê²Œ ì„ íƒê¶Œì„ ì£¼ëŠ” ë°©ì‹
def suggest_dtype_optimization(df: pd.DataFrame):
    """ë°ì´í„° íƒ€ì… ìµœì í™” ì œì•ˆ (ì‹¤í–‰í•˜ì§€ ì•ŠìŒ)"""
    
    suggestions = []
    potential_memory_save = 0
    
    for col in df.columns:
        if df[col].dtype == 'int64':
            if df[col].min() >= 0 and df[col].max() <= 255:
                suggestions.append(f"â€¢ {col}: int64 â†’ uint8 (ë©”ëª¨ë¦¬ 87.5% ì ˆì•½)")
                potential_memory_save += df[col].memory_usage() * 0.875
    
    if suggestions:
        with st.expander("ğŸ’¡ ì„±ëŠ¥ ìµœì í™” ì œì•ˆ", expanded=False):
            st.info(f"""
            ë°ì´í„° íƒ€ì…ì„ ìµœì í™”í•˜ë©´ ë¶„ì„ ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            
            **ì œì•ˆì‚¬í•­:**
            {chr(10).join(suggestions)}
            
            **ì˜ˆìƒ ë©”ëª¨ë¦¬ ì ˆì•½**: {potential_memory_save / 1024 / 1024:.1f} MB
            """)
            
            if st.button("ë°ì´í„° íƒ€ì… ìµœì í™” ì ìš©"):
                # ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ë™ì˜í•œ ê²½ìš°ë§Œ ì ìš©
                optimized_df = optimize_dtypes(df.copy())
                st.session_state.df_optimized = optimized_df
                st.success("âœ… ìµœì í™” ì™„ë£Œ!")
                
def estimate_analysis_time(n_rows: int, n_qi: int) -> int:
    """ë¶„ì„ ì‹œê°„ ì˜ˆì¸¡ (ì´ˆ)"""
    # ê²½í—˜ì  ê³µì‹ (ì¡°ì • í•„ìš”)
    base_time = 0.00001 * n_rows  # í–‰ë‹¹ ê¸°ë³¸ ì‹œê°„
    qi_factor = 1.5 ** n_qi  # ì¤€ì‹ë³„ì ìˆ˜ì— ë”°ë¥¸ ì§€ìˆ˜ì  ì¦ê°€
    return int(base_time * qi_factor)


def display_entropy_visualization(ec_stats_df: pd.DataFrame):
    """ì—”íŠ¸ë¡œí”¼ ì‹œê°í™” (ìµœì í™”)"""
    entropy_cols = [col for col in ec_stats_df.columns if col.endswith('_entropy')]
    
    if not entropy_cols:
        st.info("ì—”íŠ¸ë¡œí”¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì‹œê°í™”í•  ì»¬ëŸ¼ ì„ íƒ
    selected_entropy = st.selectbox(
        "ì‹œê°í™”í•  ì—”íŠ¸ë¡œí”¼ ì»¬ëŸ¼",
        entropy_cols,
        format_func=lambda x: x.replace('_entropy', '').replace('_', ' ').title()
    )
    
    # ë‹¨ì¼ ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(10, 5))
    
    # íˆìŠ¤í† ê·¸ë¨
    data = ec_stats_df[selected_entropy].dropna()
    ax.hist(data, bins=30, edgecolor='black', alpha=0.7)
    ax.set_xlabel('ì—”íŠ¸ë¡œí”¼')
    ax.set_ylabel('EC ìˆ˜')
    ax.set_title(f'{selected_entropy.replace("_entropy", "")} ì—”íŠ¸ë¡œí”¼ ë¶„í¬')
    
    # í†µê³„ ì •ë³´ ì¶”ê°€
    mean_val = data.mean()
    ax.axvline(mean_val, color='red', linestyle='--', label=f'í‰ê· : {mean_val:.3f}')
    ax.legend()
    
    # í‘œì‹œ
    st.pyplot(fig)
    
    # ë©”ëª¨ë¦¬ í•´ì œ ì¤‘ìš”!
    plt.close(fig)
    
    # ìš”ì•½ í†µê³„
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ìµœì†Œ", f"{data.min():.3f}")
    with col2:
        st.metric("í‰ê· ", f"{data.mean():.3f}")
    with col3:
        st.metric("ìµœëŒ€", f"{data.max():.3f}")
    with col4:
        st.metric("í‘œì¤€í¸ì°¨", f"{data.std():.3f}")


def get_score_badge(metric: str, value: Any, metric_info: Dict) -> str:
    """ì ìˆ˜ë¥¼ í‰ê°€í•˜ì—¬ ë°°ì§€ ë°˜í™˜"""
    if value is None or (isinstance(value, float) and np.isnan(value)):
        return "âšª í‰ê°€ ë¶ˆê°€"
    
    if not isinstance(value, (int, float)):
        return "âšª ë¹„ìˆ˜ì¹˜"
    
    info = metric_info[metric]
    thresholds = info['thresholds']
    lower_better = info['lower_better']
    
    if lower_better:
        if value <= thresholds['excellent']:
            return "ğŸŸ¢ ìš°ìˆ˜"
        elif value <= thresholds['good']:
            return "ğŸŸ¡ ì–‘í˜¸"
        elif value <= thresholds['fair']:
            return "ğŸŸ  ë³´í†µ"
        else:
            return "ğŸ”´ ì£¼ì˜"
    else:
        if value >= thresholds['excellent']:
            return "ğŸŸ¢ ìš°ìˆ˜"
        elif value >= thresholds['good']:
            return "ğŸŸ¡ ì–‘í˜¸"
        elif value >= thresholds['fair']:
            return "ğŸŸ  ë³´í†µ"
        else:
            return "ğŸ”´ ì£¼ì˜"